---
title: "Potential Risks of Relying on Open-Access AI Models"
date: "2025-02-10 19:00:00"
summary: "In this interview, Edoardo Madussi, Head of Business Development, Intelligencia AI discusses the potential impact of AI-driven drug discovery platforms like DeepSeek and Qwen, highlighting their democratizing potential while also acknowledging challenges related to data quality and validation. The conversation explores the potential disruptions to current R&amp;D practices, including the..."
categories:
  - "pharmexec"
lang:
  - "en"
translations:
  - "en"
tags:
  - "pharmexec"
menu: ""
thumbnail: ""
lead: ""
comments: false
authorbox: false
pager: true
toc: false
mathjax: false
sidebar: "right"
widgets:
  - "search"
  - "recent"
  - "taglist"
---

In this interview, Edoardo Madussi, Head of Business Development, Intelligencia AI discusses the potential impact of AI-driven drug discovery platforms like DeepSeek and Qwen, highlighting their democratizing potential while also acknowledging challenges related to data quality and validation. The conversation explores the potential disruptions to current R&D practices, including the acceleration of drug discovery and the optimization of manufacturing and supply chains.

The discussion also addresses the potential risks associated with relying heavily on open-access AI models, including data security, intellectual property concerns, and the potential for biases in underlying datasets. Finally, the interview touches upon the environmental impact of AI, emphasizing the energy consumption of large language models while acknowledging the potential for AI to improve efficiency and reduce the environmental footprint of drug development.

What are the potential risks associated with relying heavily on open-access AI models in terms of data security, intellectual property, and potential biases in the underlying datasets?
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

That summarizes a bit the concerns that we have discussed thus far. While the ability to leverage the predictive power of this technology is very appealing, unfortunately, we still have to do a lot of work in ensuring that the data quality is preserved prior to even utilizing these models. Now, if you add that once these models have digested the information, they provide potential hallucinations of outputs. Even more so, everything that is produced by an algo in terms of insight, so information after being processed through a machine learning or generative AI function, needs to be clearly marked as a result of AI.

From a security standpoint, the companies are arming themselves with a number of new standards that the FDA is not mandating, but is providing guidelines for to ensure that there is clearly minimal standards for its use. In fact, the FDA has just recently released a very interesting publication that every everyone in the space should be able to gain access from on their website that provides clear guidelines and really insightful information on how to handle the use of these models within the clinical trial space.

[pharmexec](https://www.pharmexec.com/view/potential-risks-relying-open-access-ai-models)
