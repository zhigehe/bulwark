---
title: "OpenAI CEO Sam Altman admits that AI’s benefits may not be widely distributed"
date: "2025-02-10 06:35:56"
summary: "In a new essay on his personal blog, OpenAI CEO Sam Altman said the company is open to a “compute budget,” among other “strange-sounding” ideas, to “enable everyone on Earth to use a lot of AI” and ensure the benefits of the technology are widely distributed. “The historical impact of..."
categories:
  - "techcrunch"
lang:
  - "en"
translations:
  - "en"
tags:
  - "techcrunch"
menu: ""
thumbnail: ""
lead: ""
comments: false
authorbox: false
pager: true
toc: false
mathjax: false
sidebar: "right"
widgets:
  - "search"
  - "recent"
  - "taglist"
---

In a [new essay on his personal blog](https://blog.samaltman.com/three-observations), OpenAI CEO Sam Altman said the company is open to a “compute budget,” among other “strange-sounding” ideas, to “enable everyone on Earth to use a lot of AI” and ensure the benefits of the technology are widely distributed.

“The historical impact of technological progress suggests that most of the metrics we care about (health outcomes, economic prosperity, etc.) get better on average and over the long-term, but increasing equality does not seem technologically determined and getting this right may require new ideas,” Altman wrote. ” In particular, it does seem like the balance of power between capital and labor could easily get messed up, and this may require early intervention.”

Solutions to this problem, like Altman’s “compute budget” concept, may be easier to propose than execute. Already, [AI is impacting the labor market](https://www.wsj.com/articles/it-unemployment-rises-to-5-7-as-ai-hits-tech-jobs-7726bb1b), resulting in [job cuts](https://www.pymnts.com/news/artificial-intelligence/2024/25percent-ceos-expect-ai-lead-job-cuts-this-year/) and [departmental downsizing](https://www.linkedin.com/pulse/ai-related-layoffs-rising-heres-what-1kflf). [Experts have warned](https://www.theguardian.com/commentisfree/2023/may/22/ai-jobs-policies) that mass unemployment is a possible outcome of the rise of AI tech if not accompanied by the right government policies and reskilling and upskilling programs.

[Not for the first time](https://techcrunch.com/2025/01/05/openai-is-beginning-to-turn-its-attention-to-superintelligence/), Altman claims that artificial general intelligence (AGI) — which he defines as “[an AI] system that can tackle increasingly complex problems, at human level, in many fields” — is near. Whatever form it takes, this AGI won’t be perfect, Altman warns, in the sense that it may “require lots of human supervision and direction”

“[AGI systems] will not have the biggest new ideas,” Altman wrote, “and it will be great at some things but surprisingly bad at others.”

But the real value from AGI will come from running these systems on a massive scale, Altman asserted. [Similar to OpenAI rival Anthropic’s CEO, Dario Amodei](https://techcrunch.com/2024/10/11/anthropic-ceo-goes-full-techno-optimist-in-15000-word-paean-to-ai/), Altman envisions thousands or even millions of hyper-capable AI systems tackling tasks “in every field of knowledge work.”

One might assume that’ll be an expensive vision to realize. Indeed, Altman observed that “you can spend arbitrary amounts of money and get continuous and predictable gains” in AI performance. That’s perhaps why OpenAI is [reportedly in talks](https://techcrunch.com/2025/01/30/openai-said-to-be-in-talks-to-raise-40b-at-a-340b-valuation/) to raise up to $40 billion in a funding round, and has [pledged to spend up to $500 billion](https://techcrunch.com/2025/01/23/openai-and-softbank-are-reportedly-putting-19b-each-into-stargate/) with partners on an enormous data network.

Yet Altman also makes the case that the cost to use “a given level of AI” falls about 10x every 12 months. In other words, pushing the boundary of AI technology won’t get cheaper, but users will gain access to increasingly capable systems along the way.

Capable, inexpensive AI models from [Chinese AI startup DeepSeek and others seem](https://techcrunch.com/2025/02/07/deepseek-everything-you-need-to-know-about-the-ai-chatbot-app/) to support that notion. There’s [evidence to suggest](https://techcrunch.com/2025/02/05/researchers-created-an-open-rival-to-openais-o1-reasoning-model-for-under-50/) that training and development costs are coming down, as well, but both Altman and Amodei have argued that [massive investments](https://www.linkedin.com/posts/alliekmiller_dario-amodei-ceo-of-anthropic-says-2024-activity-7286433413090213888-vLtl#:~:text=Dario%20Amodei%2C%20CEO%20of%20Anthropic,models%20cost%20about%20%241B.) will be required to achieve AGI-level AI — and beyond.

As for how OpenAI plans to release AGI-level systems (assuming it can, in fact, create them), Altman said that the company will likely make “some major decisions and limitations related to AGI safety that will be unpopular.” OpenAI [once pledged](https://openai.com/charter/) that it would commit to stopping competing with and start assisting any “value-aligned,” “safety-conscious” project that comes close to building AGI before it does, out of concern for safety.

Of course, that was when OpenAI intended to remain a nonprofit. The company is in the [process of converting its corporate structure into that of a more traditional, profit-driven org](https://techcrunch.com/2024/12/27/openai-lays-out-its-for-profit-transition-plans/#:~:text=The%20PBC%20will%20run%20and,as%20a%20nonprofit%20research%20lab.). OpenAI [reportedly](https://www.linkedin.com/posts/abhishekratna_openai-is-growing-fast-and-burning-through-activity-7246876772506443777-Apl9) aims to reach $100 billion in revenue by 2029, equal to Target and Nestle’s current annual sales.

This being the case, Altman added that OpenAI’s goal as it builds more powerful AI will be to “trend more towards individual empowerment” while forestalling “AI being used by authoritarian governments to control their population through mass surveillance and loss of autonomy.” Altman recently said that he thinks OpenAI has been on the wrong side of history when it comes to open-sourcing its technologies. While OpenAI has open-sourced tech in the past, the company has generally favored a proprietary, closed-source development approach.

“AI will seep into all areas of the economy and society; we will expect everything to be smart,” Altman said. “Many of us expect to need to give people more control over the technology than we have historically, including open-sourcing more, and accept that there is a balance between safety and individual empowerment that will require trade-offs.”

Altman’s blog post comes ahead of this week’s AI Action Summit in Paris, which has already prompted other tech notables to outline [their own](https://techcrunch.com/2025/02/08/ai-pioneer-fei-fei-li-says-ai-policy-must-be-based-on-science-not-science-fiction/) [visions](https://fortune.com/2025/02/09/linkedin-cofounder-reid-hoffman-hugging-face-ceo-clemen-delangue-letter-ai-public-goods-current-ai-action-summit/) for AI’s future.

In a footnote, Altman added that OpenAI does not, in fact, plan to end its relationship with close partner and investor Microsoft anytime soon by using the term AGI. Microsoft and OpenAI [reportedly had a contractual definition of AGI](https://techcrunch.com/2024/12/26/microsoft-and-openai-have-a-financial-definition-of-agi-report/) — AI systems that can generate $100 billion in profits — that would, once met, allow OpenAI to negotiate more favorable investment terms. Altman said, however, that OpenAI “fully expect[s] to be partnered with Microsoft for the long term.”

[techcrunch](https://techcrunch.com/2025/02/09/openai-ceo-sam-altman-admits-that-ais-benefits-may-not-be-widely-distributed/)
