---
title: "Anthropic CEO says DeepSeek was ‘the worst’ on a critical bioweapons data safety test"
date: "2025-02-08 07:01:05"
summary: "Anthropic’s CEO Dario Amodei is worried about competitor DeepSeek, the Chinese AI company that took Silicon Valley by storm with its R1 model. And his concerns could be more serious than the typical ones raised about DeepSeek sending user data back to China. In an interview on Jordan Schneider’s ChinaTalk..."
categories:
  - "techcrunch"
lang:
  - "en"
translations:
  - "en"
tags:
  - "techcrunch"
menu: ""
thumbnail: ""
lead: ""
comments: false
authorbox: false
pager: true
toc: false
mathjax: false
sidebar: "right"
widgets:
  - "search"
  - "recent"
  - "taglist"
---

Anthropic’s CEO Dario Amodei is worried about competitor DeepSeek, the Chinese AI company [that took Silicon Valley by storm](https://techcrunch.com/podcast/deepseek-lights-a-fire-under-silicon-valley/) with [its R1 model](https://techcrunch.com/2025/01/27/deepseek-claims-its-reasoning-model-beats-openais-o1-on-certain-benchmarks/). And his concerns could be more serious than the typical ones raised about DeepSeek sending user data back to China.

In [an interview](https://www.chinatalk.media/p/anthropics-dario-amodei-on-ai-competition) on Jordan Schneider’s ChinaTalk podcast, Amodei said DeepSeek generated rare information about bioweapons in a safety test run by Anthropic.

DeepSeek’s performance was “the worst of basically any model we’d ever tested,” Amodei claimed. “It had absolutely no blocks whatsoever against generating this information.”

Amodei stated that this was part of evaluations Anthropic routinely runs on various AI models to assess their potential national security risks. His team looks at whether models can generate bioweapons-related information that isn’t easily found on Google or textbooks. Anthropic positions itself as the AI foundational model provider [that takes safety seriously.](https://www.anthropic.com/news/core-views-on-ai-safety)

Amodei said he didn’t think DeepSeek’s models today are “literally dangerous” in providing rare and dangerous information, but that they might be in the near future. Although he praised DeepSeek’s team as “talented engineers,” he advised the company to “take seriously these AI safety considerations.”

Amodei has also [supported strong export controls](https://techcrunch.com/2025/01/29/anthropics-ceo-says-deepseek-shows-that-u-s-export-rules-are-working-as-intended/) on chips to China, citing concerns that they could give China’s military an edge.

Amodei didn’t clarify in the ChinaTalk interview which DeepSeek model Anthropic tested, nor did he give more technical details about these tests. Anthropic didn’t immediately reply to a request for comment from TechCrunch. Neither did DeepSeek.

DeepSeek’s rise has sparked concerns about its safety elsewhere, too. For example, Cisco security researchers [said last week](https://blogs.cisco.com/security/evaluating-security-risk-in-deepseek-and-other-frontier-reasoning-models) that DeepSeek R1 failed to block any harmful prompts in its safety tests, achieving a 100% jailbreak success rate.

Cisco didn’t mention bioweapons, but said it was able to get DeepSeek to generate harmful information about cybercrime and other illegal activities. It’s worth mentioning, though, that Meta’s Llama-3.1-405B and OpenAI’s GPT-4o also had high failure rates of 96% and 86%, respectively.

It remains to be seen whether safety concerns like these will make a serious dent in DeepSeek’s [rapid adoption.](https://techcrunch.com/2025/01/27/deepseek-displaces-chatgpt-as-the-app-stores-top-app/) Companies like [AWS](https://aws.amazon.com/blogs/aws/deepseek-r1-models-now-available-on-aws/) and [Microsoft](https://techcrunch.com/2025/01/29/microsoft-brings-a-deepseek-model-to-its-cloud/) have publicly touted integrating R1 into their cloud platforms – ironically enough, given that Amazon is [Anthropic’s biggest investor](https://techcrunch.com/2024/11/22/anthropic-raises-an-additional-4b-from-amazon-makes-aws-its-primary-cloud-partner/).

On the other hand, [there’s a growing list](https://techcrunch.com/2025/02/03/deepseek-the-countries-and-agencies-that-have-banned-the-ai-companys-tech/) of countries, [companies](https://techcrunch.com/2025/01/31/hundreds-of-companies-are-blocking-deepseek-over-china-data-risks/), and especially government organizations like the US Navy and [the Pentagon](https://techcrunch.com/2025/01/30/pentagon-scrambles-to-block-deepseek-after-employees-connect-to-chinese-servers/) that have started banning DeepSeek.

Time will tell if these efforts catch on or if DeepSeek’s global rise will continue. Either way, Amodei says he does consider DeepSeek a new competitor that’s on the level of the U.S.’ top AI companies.

“The new fact here is that there’s a new competitor,” he said on ChinaTalk. “In the big companies that can train AI — Anthropic, OpenAI, Google, perhaps Meta and xAI — now DeepSeek is maybe being added to that category.”

[techcrunch](https://techcrunch.com/2025/02/07/anthropic-ceo-says-deepseek-was-the-worst-on-a-critical-bioweapons-data-safety-test/)
