---
title: "为什么 Anthropic CEO 对 DeepSeek 和中国 AI 的恶意这么重？"
date: "2025-01-31 14:20:47"
summary: "一个科学家，几个月前写了一篇文章，宣示了他和他的公司通过强大的人工智能解决全人类身心健康、心理疾病..."
categories:
  - "pingwest"
lang:
  - "zh-CN"
translations:
  - "zh-CN"
tags:
  - "pingwest"
menu: ""
thumbnail: ""
lead: ""
comments: false
authorbox: false
pager: true
toc: false
mathjax: false
sidebar: "right"
widgets:
  - "search"
  - "recent"
  - "taglist"
---

一个科学家，几个月前写了一篇文章，宣示了他和他的公司通过强大的人工智能解决全人类身心健康、心理疾病、贫困、和平、工作与生活的意义等诸多方面的美好善意。几个月后，还是这名科学家，又突然发布了一篇文章，强烈呼吁不应该让任何一块美国的芯片出口到中国，以限制中国人工智能的发展，维系人工智能的“单极世界”（我很震惊他会赤裸裸地使用这个词汇）。这件事，怎么看都让人觉得割裂，以及那么一丝丝虚伪。

这个人就是人工智能公司 Anthropic 的 创始人和 CEO Dario Amodei，一名意大利裔美国人、神经物理学博士、资深 AI 科学家、昔日的 OpenAI 研究团队灵魂人物之一、中国公司百度的深度学习实验室早期员工、号称将打造最强大和安全的 AI 的理想主义者、OpenAI 最重要的竞争对手的创始人，以及现在，美国对中国 AI 全方位无死角禁运最激烈的呼吁者，没有之一。

尽管 Anthropic 和它旗下的 Claude 系列模型在中国公众当中的知名度相当有限，但毕竟，它是目前世界上最受 AI 应用开发者欢迎的大语言模型的提供者，在中国的 AI 研究人员和开发者群体中也有着相当多的拥趸。但是一夜之间，很多中国的 AI 从业者公开表示：Anthropic 和 Amodei 本人失去了他们最基本的尊重。

这就是一篇“檄文”的效应。

在这篇题为《关于 DeepSeek 和出口控制》的文章中，Dario Amodei 一方面云淡风轻指称 DeepSeek 取得的成就撼动美国 AI 的优势被夸大描述了，在表达对 DeepSeek- V3 模型创新肯定的同时，坚决不承认引发更大轰动效应的 DeepSeek 推理模型 —— R1 的取得的突破（这厮在这一问题上的心思，是本文后面论述的重点）。他更不愿意承认的是 DeepSeek 模型在算力成本和算法效率上取得的成果—— 用一个自己也承认”未经过证实”的 DeepSeek 有五万张走私而来的英伟达 A100、H100 和 H800 显卡的流言，力证 DeepSeek- V3 模型不可能用600万美元的低成本训练而成。显然，Amodei 不能接受 DeepSeek 以算法效率创新替代算力堆砌这个被日益普遍承认的路径，因此不惜用一个连他自己也知道未经验证的 DeepSeek 走私了大量高端显卡的前提实现了这个论述。但他又表述美国对中国的算力出口管制没有失效——他可能恰好忘了他前面的论述建立在 DeepSeek 走私的假设上。

![来源：https：//darioamodei.com/on-deepseek-and-export-controls](https://cdn.pingwest.com/portal/2025/01/31/portal/2025/01/31/jS20J7swEf3_9Kz2GX8BXNicP0pmp8yf.png?x-oss-process=style/article-body "来源：https：//darioamodei.com/on-deepseek-and-export-controls")

来源：https：//darioamodei.com/on-deepseek-and-export-controls

我们还原一下他的论述逻辑线条：DeepSeek 的影响力被夸大了—— V3 确实是个创新，但不可能花那么少的钱——听说他们走私了芯片——所以他们确实花了更多的训练成本—— DeepSeek 没有原创，它站在我们的研究基础上当然成本更低—— R1 推理模型绝对没有创新，只是复现 o1 的结果（装作没看见 OpenAI 已经承认了 DeepSeek 在推理上的成果是独立的发现）—— 出口管制没有失效，是对的（忘了自己前面的论述前提是 DeepSeek 获得了走私显卡）—— 我们要打造一个 AI 的单极世界，中国绝对不能做出与我们水平相当的模型（忘了开头说过 DeepSeek 不足为惧）—— 因此别说 H100 和 H800，最低端的 H20 都不能出口给中国，这样中国就赢不了了。

你看，一个处处讲逻辑和推理的科学家，试图用一篇万字长文论证一个无法自圆其说，但又要在形式上处处讲逻辑的推理的结论，他就会显得如此的笨拙，以及虚伪。

这并不是 Dario Amodei 第一次呼吁加强对中国的算力管制，你也没法要求一个美国的人工智能科学家对中国有与生俱来的善意，但他在 DeepSeek 引发了硅谷的广泛关注、肯定和一定程度的恐慌的背景下，专门鼓噪对中国的算力出口进一步管制，以及极力否定 DeepSeek 在算力效率优化和模型推理方法上的创新，是非常值得关注和解析的现象。没人期待他对中国的善意，但他对中国和中国诞生的 AI 公司 DeepSeek 的恶意和怨念如此之重，是很值得玩味的。

Dario Amodei 为什么“看不上”DeepSeek-R1 ？
----------------------------------

尽管极力推测 DeepSeek-V3 的训练成本不止于600万美元，但好在 Dario Amodei 确实承认了 V3 是真正的创新，但他又非要强调这并非突破性的，而是“持续成本降低曲线上一个预期的点”。他认为“不同之处在于，第一个展示预期成本降低的公司是中国公司，这在以前从未发生过，并且具有地缘政治意义”。这种夸人又不想真心实意夸的样子，真的是让人看着都累。我倒宁愿看 Amodei 直接说：“美国公司都在做模型成本下降的创新，只是 DeepSeek 碰巧第一个做出来了而已”，可偏偏直爽不是他具备的品质。

到了 DeepSeek-R1 的时候，Amodei 倒是直爽了起来，他绝对不肯承认 R1 是突破性的成果，在这个问题上不留任何余地，不顾就连训练出强化学习模型 o1 和 o3 的 OpenAI 都承认了 R1 在强化学习的方法上做出了原创性的突破，也装作对那些指出 DeepSeek 的强化学习摆脱了人类反馈的介入，是大语言模型 “AlphaGo 时刻”的研究结果视而不见。他坚持说：R1 只是在 V3 的基础上进行了强化学习，它的所有动作都是在复现 o1，每一家美国 AI 公司都在进行这方面的推理尝试，这是技术趋势，跟开源也没有关系，只是 DeepSeek 恰好先做出来了而已。

![](https://cdn.pingwest.com/portal/2025/01/30/Mp5xdj837TcHHB7F5e021hXM0GS772k7.PNG?x-oss-process=style/article-body)

我们倒不必因为 Amodei 的嘴硬而忿忿不平，毕竟作为公认的 AI 领域卓有成就的研究者，Amodei 对一些关键问题的看法能在很大程度上影响 AI 业界、风险投资界、华尔街乃至华盛顿特区对 DeepSeek 现象的看法。这也是他为什么必须跳出来的原因。他不是在为 OpenAI 鸣不平（他跟 OpenAI 之间的恩怨可深了去了），而是在这个时候，他必须出来给他一手创办的 Anthropic 的下一步动作，找一个有台阶的铺垫。

一个非常显著的事实是：Anthropic 迄今没有一款正式对外发布的推理模型。尽管 Dario Amodei 在接受采访时曾公开表示他对单独存在的推理模型不屑一顾——当时，他主要瞄准的当然是 OpenAI。

Amodei 的观点是：推理没有那么难，基座模型更加重要。跟他暗戳戳地夸 DeepSeek-V3 有创新但在编程等方面的评测仍弱于他的 Claude 3.5 Sonnet 模型差不多，他公开承认过 o1 取得的突破，但又不认为强化学习是实现模型推理能力增强的最佳方法。他表示，在一些具体的场景和实践方面，作为一款预训练模型的 Claude 3.5 Sonnet 展现了并不弱于 o1 的推理能力。因此，他不认为推理模型和普通模型应该分开，基于预训练的基座模型仍然是更重要的，可将推理能力包容进去。

因此，非常可能发生的是：Anthropic 计划用一种与 OpenAI 和 DeepSeek 不同的方式，实现模型推理能力的跃迁，它将很可能在 Claude 的下一代旗舰基座模型中得到体现，而且仍然采用以基于人类反馈的强化学习（RLHF）为主的方式，辅之以其它的强化学习方法（Amodei 自己说的）—— 这在路径上与 OpenAI o1的思维链（CoT）和DeepSeek R1在 AI 自主强化学习的突破都有显著不同。

完全脱胎于 OpenAI、将 OpenAI 视作最直接（几乎是唯一）竞争对手的 Anthropic，某种意义上，是 OpenAI 在 前 GPT-4 时代一系列大语言模型理念的最原教旨主义信奉者。Amodei 多次站出来否认随着训练数据枯竭，预训练出现了“撞墙”和规模效应递减的现象，并一再强调经典意义上“Scaling Law”（即模型规模持续扩大才能导致性能增强）的重要性。AI 研究者和开发者在真切地期待 Anthropic 打破 Scaling Law 和预训练模型的瓶颈，推出新一代的推理能力更强的旗舰预训练模型。

但迄今为止，Anthropic 还没推出这个东西。以它的出色模型训练和从来不搞期货发布的历史记录，有理由相信 Anthropic 正在紧张地准备这个推理能力更强的预训练模型，以证明 OpenAI 的 o1 不是实现推理能力提升的最佳路径。但随着 DeepSeek-V3 的推出，他们需要证明的东西突然一下子多了起来。

首先，DeepSeek-V3 继 o1 之后进一步证明了强化学习的独立推理模型的路径是靠谱的，甚至可能是最佳的；其次，DeepSeek-V3 验证了强化学习是能不需要人类反馈就能让 AI 自主进行深度思考的（Dario Amodei 可是基于人类反馈的强化学习的主要发明者之一）；再次，DeepSeek-V3 证明了实现这一切的训练成本是可以明显降低的。

这也就意味着，一旦 Anthropic 推出新的推理能力更强的预训练模型，它要回答比过去更复杂的问题：为什么不以强化学习为主要的训练模式？基于人类反馈的强化学习究竟比 R1 代表的自主强化学习优势在哪里？以及，你的训练成本是多少？有没有更便宜、效率更高的方式？API价格能不能降下来？(Claude API 是世界上最贵的，而 Deep Seek几乎是最便宜的）

而这些棘手的问题和麻烦，都是 DeepSeek 带来的。

因此，在推出自己的推理能力更强的新模型之前，Anthropic 的“灵魂人物” Dario Amodei 只能主动跳出来，极力降低和打消人们对DeepSeek-R1 先入为主的好印象：承认它是创新和突破是万万不能的，承认它成本真的降低了也是难以接受的。

![达里奥·阿莫迪（Dario Amodei）（来源：维基百科）](https://cdn.pingwest.com/portal/2025/01/31/WG32aA0Y47f1b73d70rp30QCw5c2Ntc0.jpg?x-oss-process=style/article-body "达里奥·阿莫迪（Dario Amodei）（来源：维基百科）")

达里奥·阿莫迪（Dario Amodei）（来源：维基百科）

这是两条路线的问题，有点“你死我活”的味道。而这两条路线，某种程度上也是在大语言模型的“后预训练时代”，经典的硅谷式模型训练和中国式模型训练的两条路径的不同表征：前者凭借算力资源的优势，通过算力堆砌的粗放式暴力美学提升模型性能；后者以算法效率作为重点，通过架构和工程的创新降低训练成本，同时提升模型性能。

Anthropic 甚至是比 OpenAI 更崇尚算力规模、模型规模和暴力美学的代表，这也导致了 Dario Amodei 这篇新发表的文章，不仅暗戳戳地释放了对 DeepSeek 的恶意，更不加掩饰地将这种恶意投射给了整个中国的 AI 领域。

Dario Amodei 为什么那么痴迷算力出口管制？
---------------------------

这不是 Dario Amodei 第一次公开呼吁加强对中国的算力出口管制，他之前就在接受采访中表达过对华算力出口管制必要且需加强的观点。美国的朋友们不应该对此表示遗憾，中国的朋友们也不必要为此愤怒，他一贯如此。

但借着“ DeepSeek 效应”，Amodei 不失时机地撰文几千字，以 DeepSeek 背后是中国人工智能可能与美国并驾齐驱的趋势，呼吁进一步加强对中国的算力管制，就显得非常有意思了。相信我，当一个美国的科学家或企业家公开地表达对中国过于亲密或敌视的态度时，他们的个人诉求是第一位的。

让我们先重新审视一下 Anthropic 是什么。

毫无疑问，它是美国也是世界当下最优秀的人工智能公司——有时甚至没有之一，Dario Amodei 是它在技术上的灵魂人物。比起贬低 DeepSeek 和谈及算力出口管制时的自相矛盾和忸怩作态，他在谈论起人工智能的愿景、局限和解释具体人工智能术语和理论的时候，呈现的确实是一种令人信服的理智、克制、清晰和精准，比他的前同事、确实不太懂技术的 OpenAI 首席执行官 Sam Altman 令人信服得多。

当然，作为 OpenAI 的主要竞争者，Anthropic 令外界印象最深的标签是“安全”，这也是 OpenAI 最被诟病的地方。当然，它也确实为安全做了很多，比如将基于人类反馈的强化学习（RLHF）无处不在植入模型训练全过程的“Constitutional AI” （宪法式人工智能）原则。“安全”是 Anthropic 的卖点，有的时候也变成了它的负累。

2024年，Anthropic 在企业级市场抢走了 OpenAI 15%的市场份额，当然是因为Sonnet 3.5 模型确实强大，另一方面则是拜“安全”的护身符所赐。不过仔细想想，主打“安全”，除了瞄准的是企业用户，还谁理应是主要的买家？

答案显而易见：政府。准确地说，是美国政府。

可在参与联邦政府和相关部门的项目上，Anthropic 作为后来者，显然没有 OpenAI 吃香。特朗普2.0 时代的首个AI 大项目——“星际之门”（Stargate），话事者是白宫，主要参与者是 OpenAI 和软银，没有 Anthropic 的份儿。

![](https://cdn.pingwest.com/portal/2025/01/31/H32J6xSMXS32B0nYsQ7hy1jRRChraMB3.png?x-oss-process=style/article-body)

尽管 Dario Amodei 随即在达沃斯论坛上奚落特朗普政府的“星际之门” 是“一团混乱”，但很显然，没有哪家 AI 企业比 Anthropic 更希望参与美国政府主导的项目。为此，他也干过一系列自相矛盾的事：

一方面，在特朗普即将正式就任前的1月6日，Dario Amodei 在《华尔街日报》发表署名文章《特朗普能确保美国 AI 的领先》，主动合作的投石问路颇为明显。

另一方面，上一届民主党政府任期尾声推出的备受争议、致力于加强监管、要求人工智能企业与政府主动分享模型研究成果的《前沿人工智能模型的安全与保障创新法案》，几乎遭到了硅谷来自进步和保守阵营的一致反对，最后被加州州长纽森拒绝签署。而我们的 Dario Amodei，几乎是全硅谷唯一赞成这一法案的人工智能企业创始人。

过去，我曾经天真地认为 Anthropic 身上有早期 Google 的影子，因为这家企业将透明化、可解释性和道德置于技术与产品的底层，有理想主义的光辉。可是，早期的 Google 是将这种原则内置在创始人和团队的价值内核里的，无论如何都并不主张靠监管和行政意志实现这一切。Google 的两名创始人，从来也没试图将自己规训为白宫的买办。但我们的 Dario Amodei 可不是这样。

可惜的是，充斥着硅谷新支持者的特朗普内阁，在人工智能发展和监管上的理念与拜登内阁大相径庭。至少目前看来，这个群体并不太买 Dario Amodei 的账。在 Amodei 发表了那篇呼吁加强对华算力管制的奇文之后，支持特朗普的风险投资机构 Andreessen Horowitz 创始人Marc Andreessen 就出来打脸了：“闭源、不透明、吹毛求疵，寻求政治垄断与开源和免费的对决，可不是美国需要的赢的方式”。

某种意义上，一心想获得联邦政府大单、希望参与国家级人工智能“大项目”，拜登内阁时期无条件支持 AI 监管，特朗普当选后又吹捧特朗普才是确保美国 AI 领先的大救星的 Dario Amodei，目前事实上陷入的是生态上的孤立。他并不在美国 AI 政策制定的核心圈子里，但他又非常想进去，这就让他必须表现出一个更激进和决绝的姿态，获得这张入场券。

在这个时候，DeepSeek 出现了，在强化学习的路径上搞得他有些被动，但又给了他一个激进表态遏制中国人工智能发展的好机会，偏偏 Anthropic 的模型训练路径依赖的又是算力堆砌的规模扩张，让他不愿意相信算法效率和工程优化真的能降低算力成本，而相信卡死算力的脖子就能断了中国 AI 的前路。而这个主张，偏偏又是白宫最容易听懂和最可能接受的。 于是，Amodei 如此痴迷于呼吁更严厉的算力出口管制，也就不难理解了。

还是忍不住感慨一句：美国新一代人工智能企业的核心人物——无论 OpenAI 的 Sam Altman 还是 Anthropic 的Dario Amodei，甚至包括 Meta 的扎克伯格和 Scale.ai 的 Alexandr Wang，他们和他们的事业接受美国“国家主义”的规训是如此的自然和迅速。而中国的大多数人工智能企业家——最新的代表就是 DeepSeek 和他的创始人梁文锋接受的“规训”则是世界主义和全球化的。这真是一个有意思的现象。

[pingwest](https://www.pingwest.com/a/302091)
