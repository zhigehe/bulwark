---
title: "DeepSeek指路算力优化路径，国产AI有望实现生态闭环"
date: "2025-02-12 07:54:29"
summary: "·DeepSeek同时考虑算法精度和系统效率。除了极致的底层优化，协同优化也可能让大模型在利用国产算..."
categories:
  - "qq"
lang:
  - "zh-CN"
translations:
  - "zh-CN"
tags:
  - "qq"
menu: ""
thumbnail: "https://inews.gtimg.com/om_ls/O2K4X3zLmD0UIVXu-Yc9Yh1YBILp06aKCJQDIKDGELhiEAA_640360/0"
lead: ""
comments: false
authorbox: false
pager: true
toc: false
mathjax: false
sidebar: "right"
widgets:
  - "search"
  - "recent"
  - "taglist"
---

·DeepSeek同时考虑算法精度和系统效率。除了极致的底层优化，协同优化也可能让大模型在利用国产算力时达到甚至超越英伟达GPU的性能。从最顶层的产品应用到底层的基础设施，大模型的每一个层级都已经形成了非常好的生态，每一个层级上都存在着优化空间。

·未来推理算力或将有2-3个数量级的提升。训练算力需求仍会有所增长，总体来看，算力需求会激增，成本会更高，但算力成本还有巨大压缩空间，单位算力成本将下降，效率得到提升。

“原来大家觉得训练模型只需要招一批算法工程师，再融一大笔钱，买一大批卡，这事就能干了。但现在不是了，现在还需要招一批懂系统的人，这是AI行业的一个很大变化。”上海交通大学长聘教轨副教授、无问芯穹首席科学家戴国浩日前在接受澎湃科技采访时表示，DeepSeek使用的训练服务算力并没有随模型尺寸等比例成倍增加，而是通过底层优化释放底层硬件性能、软硬件协同创新“压榨”算力，大模型“炼制”开始追求极致性价比。

利用2048张H800 GPU，预估不到两个月时间训练DeepSeek V3。H800每小时每卡2美元租赁成本，训练成本550万美元左右，其中不包括前期探索模型架构、消融实验等开销。戴国浩表示，DeepSeek打响生态闭环第一枪，对国产算力优化提出更清晰的路径。总体来看，算力需求会激增，推理算力或将有2-3个数量级的提升，算力成本会更高，但算力成本还有巨大压缩空间，单位算力成本将下降，效率得到提升。

![图片](https://inews.gtimg.com/om_bt/OLVBtzrhAB5hgM1gHuLApLmgv3SdkGfkSstmjkVvmgpR8AA/641)

上海交通大学长聘教轨副教授、无问芯穹首席科学家戴国浩。

**底层优化释放底层硬件性能**

拆解DeepSeek的技术报告，相对于模型架构、预训练方法和后训练方法，DeepSeek着重介绍系统架构。相比之下，国外开源模型的公开技术报告中对于系统架构的介绍篇幅较少。

戴国浩表示，DeepSeek的极致性价比来自于两大类优化，一是了解硬件细节，实现极致的底层优化；二是打通软件硬件，实现联合协同优化。前者基于确定性的算法模型及底层硬件，开展通信优化、内存优化，这些优化不改变任何程序执行结果。后者如混合精度的量化、对底层硬件的修改，扩大系统的优化空间。

例如在通信优化上，DeepSeek采用双向流水线机制，让计算和通信将近100%重叠，实现更大的专家并行，使得模型能够像流水线一样“边算边传”，这被认为是使用有限资源训练更大模型的有效手段。在底层优化上，PTX的优化使得系统和模型可以更好地释放底层硬件性能，这也是DeepSeek能够更精细控制底层硬件、实现“边算边传”的重要原因。

训练一个大模型，首先要有GPU。但开发者并不需要关注底层硬件的模样，只需要通过Python等高层次语言或英伟达CUDA等硬件接口进行编程，最终调用底层的GPU。而能够直接和底层硬件发生交互的PTX一般被隐藏在CUDA的驱动中，PTX是比CUDA更底层的硬件接口编程语言。越接近底层的语言对硬件的利用效率越高，在同样硬件能力下实现更精细的通信任务管理，将最费时的跨界点通信效率提升60%，跑出效果更好的模型。

PTX编程并非行业机密，但此前几乎所有大模型算法工程师不会接触到这一层语言。因此，如果能够编程和调用PTX，就可以更好地调用底层硬件。不过，戴国浩解释，这并不意味着绕过了英伟达CUDA的垄断。从编程范式来看，DeepSeek在某些代码上绕过了CUDA的编程，但并未完全绕开CUDA生态。

**软硬件协同创新“压榨”算力**

“从最顶层的产品应用到底层的基础设施，大模型的每一个层级都已经形成了非常好的生态，每一个层级上都存在着优化空间。”戴国浩表示，除了极致的底层优化，协同优化也可能让大模型在利用国产算力时达到甚至超越英伟达GPU的性能。“原来的算法架构只考虑算法精度，大家觉得只要算法足够好就行了，但DeepSeek同时考虑算法精度和系统效率。”

例如英伟达H800集成了FP8计算单元，戴国浩表示，使用更低精度训练，理论上可带来2倍的计算加速和50%的显存降低。但由于低精度训练极易损失模型效果，以及大模型高昂的试错成本，开源社区中尚无项目实现大规模FP8预训练落地。而DeepSeek实现了FP8低比特训练出高质量模型，坚定“榨干”硬件所有潜力。

DeepSeek采用MLA（隐空间注意力计算机制）架构和MoE（混合专家模型）架构，MLA架构可进一步降低推理消耗的内存。在模型训练过程中，MoE架构采用1个共享专家和256个路由专家，每个token激活8个路由专家。

据介绍，MoE架构训练超大模型，最大的挑战是负载均衡。DeepSeek引入一个专家偏见（expert bias），保证专家负载均衡，提升集群效率。专家偏见只影响专家路由，不产生任何梯度影响。专家偏见动态调整，如果某个专家过载，就会降低偏见，如果某个专家负载不足，就会增加偏见。DeepSeek采用MoE架构，又在算法和软件层面解决了MoE本身由于专家并行带来的通信开销问题，充分挖掘了算法、软件、硬件协同创新。

**打响国产AI生态闭环第一枪**

“无论是底层优化，还是协同优化，必须要对底层硬件和系统有非常深刻的理解，既要懂算法，又要懂硬件。”戴国浩表示，以PTX编程为例，这需要开发者清晰了解英伟达的硬件是如何制造的，因此门槛高，大模型公司少有对PTX编程。业内拥有系统优化能力的团队懂PTX编程，但模型训练本身投入大，难以持续优化。

DeepSeek打响了第一枪，对国产算力优化提出了更清晰的路径。降低算力成本是国内发展大模型的核心之一。软硬件协同路径包含模型、系统、芯片等关键因素，在国外，这三者已经形成了完备的闭环生态。戴国浩表示，在以往的认知中，使用国外的芯片预训练、使用国外的模型做微调，得到的模型跟国外的闭源或开源模型相比总存在一定差距，国内的系统、芯片也难以形成闭环生态。但DeepSeek的出现使得国内的模型超越了国外的模型，软硬件协同降低了算力成本，这套方法论可以打破现在的闭环生态瓶颈。

戴国浩说，DeepSeek在论文中单独用2页文字提出对于未来硬件设计的发展建议，进一步佐证了模型、系统、硬件的闭环路线。国外的闭环AI生态始终是一个同构的AI系统，其核心竞争力就在于CUDA-X的垂直整合能力。因此，他认为，未来国内AI发展要通过调动跨越软硬件和上下游生态，加大模型、芯片、系统协同优化和垂直打通，例如根据新一代模型架构来定义未来芯片的底层电路实现、根据国产AI系统的互联通信方式设计高效的混合专家模型架构。

“如何将国内的模型、系统和芯片形成自主可控的闭环，这是未来一定会发生的事。”戴国浩表示，DeepSeek的崛起对国产算力的发展是好消息。未来推理算力或将有2-3个数量级的提升。训练算力需求仍会有所增长。总体来看，算力需求会激增，成本会更高，但算力成本还有巨大压缩空间，单位算力成本将下降，效率得到提升。

戴国浩判断，未来大模型的发展趋势，一是继续国产化，二是极致的软硬件协同优化带来成本下降，提升模型训练和应用的极致性价比。性价比越高，算力需求量就越大，算力越吃紧。当前中国算力生态存在供不应求和供过于求的双重矛盾，中国特有的AI基础设施格局是多模型和多芯片，存在大量异构算力，需要把他们变得能用、好用，在使用闭环中形成硬件和算法的正向循环。戴国浩表示，要通过软硬协同和多元异构压榨算力，降低获取强大基座模型的成本，解决算力缺口，以有限算力实现国产模型能力赶超。

[qq](https://new.qq.com/rain/a/20250212A01FX700)
