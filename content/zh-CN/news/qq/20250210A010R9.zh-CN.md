---
title: "专家访谈汇总：AI助手大洗牌"
date: "2025-02-10 07:00:00"
summary: "1、《DeepSeek引发广泛关注，大模型应用落地将加速》■DeepSeek-V3（发布于2024年..."
categories:
  - "qq"
lang:
  - "zh-CN"
translations:
  - "zh-CN"
tags:
  - "qq"
menu: ""
thumbnail: ""
lead: ""
comments: false
authorbox: false
pager: true
toc: false
mathjax: false
sidebar: "right"
widgets:
  - "search"
  - "recent"
  - "taglist"
---

**1**  
**、****《****DeepSeek引发广泛关注，大模型应用落地将加速****》**  

■

**DeepSeek-V3**（发布于2024年12月26日）是深度求索（DeepSeek）自研的MoE（Mixture of Experts）大模型，拥有671B参数，激活37B，经过14.8T tokens的预训练。

■

其在多个评测中超越了Qwen2.5-72B和Llama-3.1-405B等开源模型，并与GPT-4o和Claude-3.5-Sonnet等顶尖闭源模型性能相当。

■

**DeepSeek-R1**（发布于2025年1月20日）是针对复杂推理任务的高性能大模型，与OpenAI的模型o1性能对齐。

■

**DeepSeekApp**（AI助手）发布后，在140个市场成为最受欢迎的应用，尤其是在苹果AppStore中长期排名全球第一。

■

DeepSeek的低训练成本和开源特性大幅降低了大模型的应用门槛，推动了AI在端侧、教育、金融、医疗等多个行业的快速落地。

■

DeepSeek大模型与国产AI芯片的适配逐步成熟，有望推动国产AI芯片在训练和推理端的应用，加速国产芯片产业链发展。

■

DeepSeek系列大模型展现出与国际领先模型相媲美的能力，开源、低成本、高性能的优势为AI产业的广泛应用提供了新的契机。

**2、****《****DeepSeek惊艳世界，算力与应用将迎来结构性变化》摘要**  

■

DeepSeek-V3在开源大模型排行榜中名列榜首，并与世界最先进的闭源模型（如OpenAI的GPT-4）不分伯仲。

■

通过**FP8精度训练**、**DualPipe双向流水线**等技术创新，极大地降低了训练成本，并通过**MoE负载均衡**和\*\*多头潜在注意力机制（MLA）\*\*等优化，降低了推理成本。

■

采用多Token预测（MTP）和模型蒸馏等方法提升了性能，同时保持较低的训练与推理成本，标志着DeepSeek在大模型领域的技术突破。

■

R1的设计通过**数据引导**和**多阶段优化**平衡了推理性能和实用价值，致力于打造符合人类偏好的通用推理模型。

■

虽然DeepSeek在训练端通过优化算法与架构大幅降低了算力需求，但随着AI模型性能要求的不断提高，庞大的训练集群仍将成为行业竞争的核心。

■

由于DeepSeek模型显著降低了推理成本，推理算力的需求预计将呈现快速增长，成为AI算力的主要推动力。

■

此过程中，算力需求的结构可能会发生转变，尤其是在美国进一步收紧AI芯片供应的背景下，国产芯片厂商将迎来更多机会。

■

DeepSeek的低推理成本、强大推理能力和开源特性为AI应用的广泛落地提供了关键推动力，解决了此前推理能力不足和闭源模型成本高的问题。

■

随着AI技术特别是推理能力的突破，应用逐步进入落地期，投资者应关注行业整体性机会及国产算力企业的潜力。

****3、******《****关注DeepSeek推动AI应用带来的推理需求》摘****要**

■

训练卡主要用于大模型的训练，以英伟达的H100、A100为主，性能要求较高，需求增长主要来自大模型的研发。

■

推理卡主要用于已训练好的模型的推理，应用场景更为广泛，推理卡包括英伟达的A30、A10、T4，以及消费级的4090等。

■

DeepSeek发布的R1模型通过强化学习（RL）路径，实现了大模型训练与推理成本的大幅降低，进一步推动了推理卡需求的爆发。

■

过去，AI训练卡几乎由**英伟达**独家供应，且其所需的先进工艺（如3D堆叠）主要由**台积电**代工。

■

然而，推理卡对工艺要求相对较低，国产12nm工艺也能够满足推理卡的需求，这为国产供应链提供了巨大的市场空间。

■

国内IC设计公司如**天数智芯**、**沐曦**、**燧原**、**登临**等已经着手将推理卡移植到国产供应链上，尤其是与**中芯国际**等国产代工厂合作，推动了国产推理卡的发展。

■

以华为昇腾310为例，每片12寸晶圆可产出约150个推理卡，若我国推理卡市场需求为200亿，则需要约6600片12寸晶圆才能满足需求。

■

以华为昇腾910B为例，每片12寸晶圆可产出约17个训练卡，按目前市场需求推算，100亿资本投入对应约5000台GPU服务器，所需的训练卡数量庞大，需要约2300片12寸晶圆。

  


**4****、****《********本地模型部署需求爆发，AIPC换机加速》摘要**

  


■

传统PC用户对AI能力的需求受到**预训练大模型能力不足**和**国外API调用限制**的影响，换机动力较低。

■

**DeepSeek等开源模型降低了本地部署成本**，推理表现优异，用户可通过**AnythingLLM、Ollama**等工具实现AI本地部署，满足数据隐私保护及个性化优化需求。

■

蒸馏后的模型参数规模涵盖1.5B/7B/8B/14B/32B/70B，其中32B及以上的模型性能显著提升，但对硬件要求较高（如24GB+ GPU、大容量内存、强散热与电磁屏蔽）。

■

2028年AIPC出货量预计**达2.05亿台，占比70%**，2024-2028年复合年增长率（CAGR）高达**44%**。

■

消费级AI笔记本均价**5500-6500元**，AI台式机均价**4000元**，AIPC换机潮将**推动PC产业整体向中高端升级**。

■

**联想集团（Lenovo）**作为行业龙头，2024年PC出货量同比增长**4.7%（6180万台）**，市占率全球第一，预计2025年将**深度受益AIPC换机潮**。

**5、《****关于DeepSeek****》摘要**  

■

**DeepSeek影响力出圈**，成为科技领域新的**产业催化剂**，推动AI应用端和推理需求爆发，形成新一轮A股投资机遇。

■

TMT板块可能出现高低切换，受益于产业催化剂的**计算机/传媒**、AI端侧和应用领域可能迎来资金流入。

■

AI产业从**主题驱动**转向**业绩驱动**，AI应用端有望大规模落地，带动相关行业成长，科技成长风格占优。

■

参考**智能手机（2013-2015）→移动互联网**的产业路径，AI+时代的产业链演进路径可能是：**硬件 → 基础设施 → 终端 → AI应用（AI+）**

■

DeepSeek的突破是国产AI产业的里程碑，**短期催化AI端侧和应用板块，中期推动AI产业进入业绩兑现期**。

[qq](https://new.qq.com/rain/a/20250210A010R900)
