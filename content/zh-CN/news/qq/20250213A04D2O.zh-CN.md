---
title: "“AI那么火，但我还是劝你谨慎用它”"
date: "2025-02-13 13:51:11"
summary: "文 | 听筒Tech尽管AI已经火爆全球，但依然有不少人对它的使用存在置疑。晓姐是一名文字工作者，自..."
categories:
  - "qq"
lang:
  - "zh-CN"
translations:
  - "zh-CN"
tags:
  - "qq"
menu: ""
thumbnail: "https://inews.gtimg.com/om_ls/OdXC5KEktrc1wJpX9_oo1CeLThmClXJAJyaKoh2QwMtx8AA_640360/0"
lead: ""
comments: false
authorbox: false
pager: true
toc: false
mathjax: false
sidebar: "right"
widgets:
  - "search"
  - "recent"
  - "taglist"
---

> 文 | 听筒Tech

尽管AI已经火爆全球，但依然有不少人对它的使用存在置疑。

晓姐是一名文字工作者，自大模型推出伊始，她便尝试借助AI工具写作，但自始至终，她都无法相信AI。

“大模型刚推出的时候，大家都知道它‘资料更新不及时’，后来，随着应用不断升级，我也习惯了用大模型，但仍会对它生成的内容持迟疑态度。尤其大模型给出的数据和时间，几乎很少标注信息来源和出处，这点我必须要做一番考证。”

在晓姐看来，大模型的行文方式和生成作品，“更像结论和观点。”简单来说，大模型给出的是逻辑和结论，但写文章和做研究，只有远远是不够的，“我们讲究每一句发言是有迹可循，只有被敲打和反复考证过的传播，才有价值。”

实际上，晓姐遇到的情况，并不是偶发。近期，越来越多的博主在社交平台发出警示，告诫网友“警惕AI幻觉”，不少博主指出，**AI的强逻辑，让网友产生幻觉，认为“AI完全正确”，但实际上，不少迹象表明，AI经常出现“一本正经胡说”的现象。**

Vectara平台最新发布的数据还显示，目前市场上AI大模型，均有幻觉率，即便是OpenAI-o3，也有0.8%的幻觉率；目前市场大热的DeepSeek-V3，幻觉率达到3.9%。而在更早之前，这一幻觉率甚至高达30%。

![图片](https://inews.gtimg.com/om_bt/OUZrtS10el5q605WlhYtT2MgKl3LUbrhCJkkNBVK5NzzwAA/641)

图：市场主流大模型幻觉率（截止2025年1月31日）

公开的报道显示，此前，Vectara公司联合创始人阿姆尔·阿瓦达拉亦表示，在训练过程中，AI模型会压缩数万亿个单词间的关系，随后通过庞大的网络模型重新展开这些信息。**尽管这些模型能够重构出接近98%的训练内容，但剩下2%内容却会“误入歧途”，生成不准确或虚假信息。**

这就意味着，至少在目前，AI依然无法完全信任。不少业内人士亦对《听筒Tech（ID：tingtongtech）》表示，在专业的领域，建议警惕使用AI，“我们可以借助AI来辅助我们的工作，而不是依赖AI。”

************“AI很强大，但我不怎么用”************
--------------------------------------

晓姐是在朋友安利下开始使用AI。

十年文字工作者的晓姐，日常资料梳理的工作量非常大。前两年，大模型刚兴起的时候，晓姐就在朋友的建议下成为最早使用大模型的那一批人。

“快速响应，内容强大，逻辑也足够清晰。”这是晓姐对大模型的直观感受。一度，她热衷使用大模型，每逢写作都要问“模”。

但很快，晓姐发现，大模型不能满足她的写作需求，甚至让其创作也不够“丝滑”。

实际上，大模型刚推出的时候，有的资料确实更新不及时，会误导晓姐的文字创作。再者，晓姐发现，大模型给出的内容通常是结论和观点，虽然逻辑性很强，但一旦出现细节和事实错误，就会给晓姐的工作带来致命的打击。

“比如，使用大模型的人会发现，模型生成内容的数据和时间，几乎不标注信息来源和出处，在写作过程中，我还发现了有名言出处错误的事实，所以，我现在对AI持迟疑态度。”

高校任职的林哥也一度无法完全拥抱AI。

“如今AI已经非常强悍了，但我还是在坚持手工敲字，这与正确错误无关，完全是个人爱好。”

林哥在批阅学生的作业和论文的时候发现，“有些学生的内容一看就是AI生成，引用也‘张冠李戴’，甚至出现凭空捏造的‘AI幻觉’，我改了一部分就坚持不下去，AI增加了我的工作量。”

“这并不是一个好的引导和风向。当你越来越认为本就应该如此的时候，那么你就失去了对文字和内容的审美鉴别，也失去了对事实的判断和认识能力。”林哥表示。

![图片](https://inews.gtimg.com/om_bt/OQIXjizcQeQ5b5zCCOTh8C76gRQtPzmbQQDjnM6bQyXkkAA/641)

图：社交平台关于“AI幻觉”的讨论 来源：小红书，《听筒Tech》截图

95后家装设计师小屈告诉《听筒Tech》，尽管自己是网络拥护者，但也很少使用AI绘图。

其实，在大模型刚出来的时候，小屈是兴奋的，“画图是非常累的，客户的需求也非常多，现在的家装行业，通常有了初步的设计图纸，客户才会缴纳意向金。我每天的工作不是跟客户沟通设计需求，就是在画图。且画的图都不一定会被客户采用，所以工作量非常大。”

AI绘图出现后，小屈抱着试试的心理去AI作图。不过，在尝试了几次后，小屈放弃了作图。目前，他只是用AI编辑一些文案。

“主要问题在于不够精准，每个空间不能统一设计手法。”在小屈看来，AI绘图只能作为辅助，或者作为早期工作意向确认工具。

同样的问题，也发生在视频生成领域。

在AI软件席卷行业的最早期，影视就被认为是被冲击的巨大行业。后来，随着细分领域模型的不断推出和升级，影视行业从业者郭哥十分焦虑。他曾和《听筒Tech》交流，要主动学习AI技术，避免在行业的内卷中被淘汰。

但郭哥发现，以全网都在吹的某平台为例，生成的视频有几个明显的缺点，比如图人和物体之间存在交互失灵、物理引擎失效、对象突然冒出等使视频产生“鬼畜感”。

**********“小心****AI****一本正经胡说”**********
----------------------------------------

在晓姐和小屈看来，目前不敢将专业的工作交给AI来做，“或许有一天我会信任它，但不是现在。”

关于“我为什么不用AI”，在社交平台，网友也众说纷纭。有人表示，“我完全不觉得AI生成的短片有趣，因为创作这个东西的不知道痛楚为何物”、“有没有人感觉越用AI越蠢，这学期用AI辅写，被导师吐槽了几遍文章写作水平不行”、“越来越不会内容输出了”......

尤其是，“AI幻觉”一词最近被提及得越来越多。

一位博主表示，“小心AI一本正经的‘胡说’。”实际上，**AI“强逻辑”幻觉的背后，存在“一本正经胡说”的隐患，且不是自己的专业和领域根本判断不了。**

该博主表示，尤其是AI在回应一些严肃知识性问题时，会存在凭空编造事实、杜撰不存在文献的可怕现状。

科普作家河森堡表示，自己让某大模型介绍一下“青铜利簋”，它就开始一本正经地胡扯，说这件青铜器是商王帝乙为祭祀自己父亲所铸，还详述了其内壁的铭文。

不过，河森堡曾经在博物馆看见过“利簋”这件文物，此物是西周贵族为了纪念武王推翻商朝而铸，铭文和祭祀也与商王毫无关系。

实际上，河森堡还继续追问AI，这些资料都是从哪看来的，AI列出了一大堆文献，但他发现，文献和作者介绍不少是“捏造”的。

另一位博主也呼吁大家“警惕AI幻觉”、“希望大家使用AI时，甄别它的谎言”。

该博主表示，“体验了DeepSeek，一开始看到它如此强大的推理能力，特别是它在自我思考的时候展现出来的完整思维链，确实非常惊艳。”

但当自己在问怎样看待“创新是一种涌现”这个话题时发现，尽管大模型给出了一系列层次和角度的分析，但博主却总感觉“有一丝丝的不对”。

该博主认认真真地对内容做了核对，发现这些看似正确的回答却有很多问题。比如，AI在“编造数据谎言”。实际上，针对DeepSeek表示的“70%的创新出现在跨学科领域”，该博主查了很多文献都没有找到这个信息源头和实验数据。

该博主指出，“如果这种捏造广泛流传，不知有多可怕。”

甚至，如果AI能虚构文本、照片乃至视频的一切内容，并且令其彼此之间相互印证和支撑，其制造幻觉的强度与编撰故事不可同日而语。

**“除非你亲自见到并本人求证，或者到现场实地考察，否则你会被AI创造出的假象玩得死死的。”**一位业内人士这样担忧。

然而，在现实社会中，有意愿和有能力亲自验证事实的人并不多。也就是说，稍一个不留神，你可能就会被AI污染。

**********别焦虑，现在******A**************************I还无法取代你我**********
-------------------------------------------------------------------

实际上，AI幻觉已经给人们的工作和现实生活带来了巨大影响。

世界经济论坛发布的《2025年全球风险报告》显示，错误和虚假信息是2025年全球面临的五大风险之一。2023年，美国律师史蒂文·施瓦茨也曾因“轻信”ChatGPT，在法庭文件中引用了并不存在的法律案例。而在医学领域，AI幻觉提供的错误诊断和治疗建议，可能会危及患者生命。

**从底层技术来看，AI幻觉的产生，是必然的。**

AI企业落地师石云升便告诉《听筒Tech》，“据我所知，目前AI底层架构师无法解决幻觉问题。因为它每一个字符都根据概率计算，这就导致它输出的内容会有幻觉，这是无解的。”

不过，石云升指出，**在真实场景中，用户可以通过反复沟通来帮助AI更精准的回答问题。**毕竟，AI给出的答案是否采纳，最终还是由人来决定。

“**降低AI幻觉的问题可以通过’预训练、微调和推理‘三个层级来解决。**”石云升指出，例如，在公司负责AI客服时，用户主要通过“提示词+知识库”来防止AI输出幻觉，“如果公司有懂得微调的技术人员，并且拥有优质的企业数据，微调的效果会更加理想。”

不过，石云升坦言，微调通常是针对企业专属的大模型进行的，“一般我们会在通用大模型回复效果特别不好的情况才会考虑微调。”

比如，在法律领域，通用大模型训练预料数量太少，质量太差，企业内部有很多更优质的法律数据，这种情况就可以考虑微调一个专属公司的法律大模型，微调后出现幻觉的概率就小很多。

石云升指出，还有一种手法是使用“RAG增强检索”，“在提问的时候，先从知识库里查询资料，然后给到大模型，如果用户的问题在知识库里有资料，那基本也不会出现AI幻觉。”

当然，石云升也表示，**对于普通用户来说，AI的幻觉率，目前没有特别有效的解决办法，**“普通用户很难接触到预训练和微调技术，因此只能在AI推理阶段提供更详细的信息。这也是为什么在AI刚刚兴起时，行业内很多人开始教授如何编写‘提示词’并建立自己的知识库。”

也即是说，至少在现阶段，AI还无法真正取代你我。

此前，张雪峰“回应DeepSeek会让自己失业”这一话题时曾这样解释，“第一，我们这个行当不止是打破信息差，还是在提供情绪价值；第二，大模型只会有一些公开信息，但是你要知道有些信息网上是不公开的。”

那些“网上非公开的”、“对情感的理解”，以及“深度思考引发的创新”，或许是现阶段“你我”存在的价值和意义所在。

“警惕AI幻觉，这是一种呼吁，也是一种社会职责。”显然，这不是“晓姐”一个人所希冀的事。

（文中晓姐、林哥、小屈、郭哥均为化名。）

**更多精彩内容，关注钛媒体微信号（ID：taimeiti），或者下载钛媒体App**

[qq](https://new.qq.com/rain/a/20250213A04D2O00)
