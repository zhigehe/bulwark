---
title: "豆包又把算力成本“打了下来” 但压力才刚刚开始"
date: "2025-02-12 19:30:13"
summary: "《科创板日报》2月12日讯（记者 张洋洋）今日，字节跳动豆包大模型团队提出了全新的稀疏模型架构 Ul..."
categories:
  - "qq"
lang:
  - "zh-CN"
translations:
  - "zh-CN"
tags:
  - "qq"
menu: ""
thumbnail: ""
lead: ""
comments: false
authorbox: false
pager: true
toc: false
mathjax: false
sidebar: "right"
widgets:
  - "search"
  - "recent"
  - "taglist"
---

**《科创板日报》2月12日讯（记者 张洋洋）**今日，字节跳动豆包大模型团队提出了全新的稀疏模型架构 UltraMem，该架构有效解决了MoE推理时高额的访存问题，推理速度较 MoE 架构提升2-6倍，推理成本最高可降低83%。

目前，国内外大模型领域的竞争愈发激烈，已然进入白热化阶段。豆包在AI基础层和应用层上均进行了全面布局，并持续迭代升级。

**▍大模型持续降本增效**

根据豆包大模型团队的研究，在Transformer架构下，模型的性能与其参数数量和计算复杂度呈对数关系。随着LLM规模不断增大，推理成本会急剧增加，速度变慢。

尽管MoE（混合专家）架构已经成功将计算和参数解耦，但在推理时，较小的batch size就会激活全部专家，导致访存急剧上升，进而使推理延迟大幅增加。

字节跳动豆包大模型Foundation团队提出了UltraMem，这是一种同样将计算和参数解耦的稀疏模型架构，在保证模型效果的前提下解决了推理的访存问题。

实验结果表明，在参数和激活条件相同的情况下，UltraMem在模型效果上超越了MoE，并将推理速度提升了2-6倍。此外，在常见batch size规模下，UltraMem的访存成本几乎与同计算量的Dense模型相当。

可以看到，不论是训练端还是推理端，大模型厂商均在力争降本增效。核心原因是随着模型规模的扩大，推理成本和访存效率已成为限制大模型规模应用的关键瓶颈，而DeepSeek已经走通了“低成本高性能”突破的这条路。

岩芯数智CEO刘凡平在接受《科创板日报》记者采访分析认为，**降低大模型的成本，业内更倾向于从技术和工程层面进行突破，实现架构优化的“弯道超车”。基础架构，如Transformer架构成本依旧高企，新的架构研究必须要有；基础算法，主要是反向传播算法，这类算法可能是深度学习的瓶颈。**

在刘凡平看来，短期内，高端芯片市场仍然还是会由英伟达主导。推理应用市场需求在增加，国产GPU公现在也有机会。从长期来看，算法一旦创新出的结果，还是比较惊人，整个算力市场需求后期有待观察。

**▍豆包的压力才刚刚开始**

在刚刚过去的春节，DeepSeek以其低廉的训练成本和高效的运算效率迅速火爆全球，成为AI领域的黑马。**目前，国内外大模型领域的竞争愈发激烈，已然进入白热化阶段。**

DeeSeek是目前国内大模型中，豆包最强劲的对手，前者在1月28日的日活跃用户数首次超越后者。目前DeepSeek的日活数据已经突破4000万，成为中国移动互联网历史上第一个上线不足一个月，但闯进全网日活Top50的应用。

近几日，豆包大模型团队连续发力。两天前，其刚刚发布视频生成实验模型“VideoWorld”，不同于 Sora 、DALL-E 、Midjourney 等主流多模态模型，VideoWorld 在业界首次实现无需依赖语言模型，即可认知世界。

目前，豆包在AI基础层和应用层进行了全面布局，并持续迭代升级。其AI产品矩阵已涵盖多个领域，如AI聊天助手豆包、猫箱、即梦AI、星绘、豆包MarsCode等。

2月12日，豆包概念股午后快速走高。据Wind数据显示，抖音豆包指数2月以来累计涨幅已超15%。个股方面，博彦科技强势涨停，汉得信息快速拉升一度涨停，广和通、先进数通等盘中冲高。

中信证券此前发布研报认为，豆包AI的生态扩张将引发新一轮巨头的技术投资周期。AI产业具有强网络效应和规模效应，当头部AI应用获得用户领先优势后，其模型精准度、边际成本以及用户粘性等竞争优势将逐渐加强。

豆包用户数持续增长，基于豆包AI的应用生态将有望加速，一方面，将催化公司对AI训练及推理算力基础设施投资，另一方面，豆包AI的快速增长将刺激其它巨头厂商加大对AI基础设施投资。

但是对于豆包自己而言，与尖子生DeepSeek的较量或许才刚刚开始。

作为一个开源模型，DeepSeek的低成本和高性能正在改变不少公司的模型选择策略。目前，华为、百度等公司旗下的不少AI应用都宣布了接入DeepSeek，甚至字节跳动自己，旗下的飞书的多维表格功能已接入DeepSeek-R1模型，火山引擎也做了适配。

据《科创板日报》记者了解，目前，豆包团队内部还在讨论豆包App是否要接入DeepSeek，从用户体验的角度来讲，选择一个效果更优的模型无可厚非，但是放弃自家模型选择友商，也很难向股东交代。这还不考虑，新增模型接入，增加适配负担等问题。

（科创板日报记者 张洋洋）

[qq](https://new.qq.com/rain/a/20250212A08EWP00)
