---
title: "业界首个！豆包新模型搅动AI视觉"
date: "2025-02-10 15:09:08"
summary: "《科创板日报》2月10日讯（编辑 宋子乔） 2月10日，A股视觉认知概念股午后大幅走强，创业板星宸科..."
categories:
  - "qq"
lang:
  - "zh-CN"
translations:
  - "zh-CN"
tags:
  - "qq"
menu: ""
thumbnail: "https://inews.gtimg.com/om_ls/OdTAMMJ-I5aklB6DndNhbrpzwIjsETC6i-3VfgstJT5NgAA_640360/0"
lead: ""
comments: false
authorbox: false
pager: true
toc: false
mathjax: false
sidebar: "right"
widgets:
  - "search"
  - "recent"
  - "taglist"
---

**《科创板日报》2月10日讯（编辑 宋子乔）** 2月10日，A股视觉认知概念股午后大幅走强，创业板星宸科技直线拉升涨停，全志科技、富瀚微、虹软科技等纷纷大幅冲高。

![图片](https://inews.gtimg.com/om_bt/OUBXi-lcyhlpIrcmTzFwKBDK6w0STw3zFfNLpKhQu_FkgAA/641)

消息面上，豆包发布视频生成实验模型“VideoWorld”。据介绍，不同于Sora、DALL-E、Midjourney等主流多模态模型，**VideoWorld在业界首次实现无需依赖语言模型，仅通过“视觉信息”即可认知世界**，也就是说，VideoWorld可通过浏览视频数据，让机器掌握推理、规划和决策等复杂能力。团队实验发现，仅300M参数量下，VideoWorld已取得可观的模型表现。

目前，该项目代码与模型已开源。

![图片](https://inews.gtimg.com/om_bt/OAKycxRHFc8cz83NAQneFgzwD7W1ejGZX1bSZPj3B7rxgAA/641)

现有模型大多依赖语言或标签数据学习知识，很少涉及纯视觉信号的学习。VideoWorld选择去掉语言模型，实现了统一执行理解和推理任务。

**怎么做到的？**

豆包大模型团队称，**VideoWorld基于一种潜在动态模型（Latent Dynamics Model，LDM），可高效压缩视频帧间的变化信息，在保留丰富视觉信息的同时，压缩了关键决策和动作相关的视觉变化，显著提升知识学习效率和效果**。

在不依赖任何强化学习搜索或奖励函数机制前提下，VideoWorld达到了专业5段9x9围棋水平，并能够在多种环境中，执行机器人任务。

但该模型并不完美，其在真实世界环境中的应用，仍面临着高质量视频生成和多环境泛化等挑战。这一点最直观体现在，视频中存在大量冗余信息，会大大影响模型的学习效率，使得视频序列的知识挖掘效率显著落后于文本形式，不利于模型对复杂知识的快速学习。

大模型的视觉理解能力一直是AI前沿研究方向之一。对人类而言，与语言相比，“用眼睛看”是门槛更低的认知方式。正如李飞飞教授9年前TED演讲中提到“幼儿可以不依靠语言理解真实世界”。

AI视觉学习，简单来说，需要大模型理解物品/空间/场景的整体含义，并根据识别内容进行复杂的逻辑计算，根据图像信息更细腻地表述并创作。

AI视觉学习能力提升，有望催发更多的AI应用。长城证券此前发布研报称，国内AI大模型多模态能力正持续提升，如快手可灵AI大模型、字节豆包AI大模型等视频生成的效果正在持续提升，包括精准语义理解、一致性多镜头生成、动态运镜等。受益于底层技术能力的升级，国内AI应用持续迭代，token调用量持续增长，AI应用有望从中受益。

（科创板日报 宋子乔）

[qq](https://new.qq.com/rain/a/20250210A04XGA00)
