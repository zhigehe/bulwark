---
title: "OpenAI、百度升级价格战 免费成大模型“标配”"
date: "2025-02-14 17:00:01"
summary: "21世纪经济报道 孔海丽DeepSeek大幅拉低了大模型开发与应用成本，将压力传导给了所有厂商。2月..."
categories:
  - "qq"
lang:
  - "zh-CN"
translations:
  - "zh-CN"
tags:
  - "qq"
menu: ""
thumbnail: ""
lead: ""
comments: false
authorbox: false
pager: true
toc: false
mathjax: false
sidebar: "right"
widgets:
  - "search"
  - "recent"
  - "taglist"
---

21世纪经济报道 孔海丽

DeepSeek大幅拉低了大模型开发与应用成本，将压力传导给了所有厂商。

2月13日凌晨3点，OpenAI火力全开，其首席执行官塞姆·奥特曼（Sam Altman）宣布，将很快发布GPT-5，并且免费无限使用。

北京时间13日上午，文心一言官宣，将于4月1日0时起全面免费，并且，即日起上线深度搜索功能。

这背后，既是大模型成本的不断降低，也可以理解为，DeepSeek一定程度上拉开了真正的AI竞争——用户流量争夺也像技术迭代一样，激烈异常。

包括阿里、字节、百度等AI大厂知情人士告诉21世纪经济报道记者，DeepSeek突然爆火，让这个春节假期变成了“紧急加班期”。

“我们原本预判，C端认知分水岭不会这么快到来，市场非常大、未来足够远，但是DeepSeek虹吸了海量消费者，今年我们会花大力气做to C的产品开发和推广。”国内一家大厂AI从业者说。

另有一位不愿具名的科技大厂AI相关岗位人士告诉21世纪经济报道记者，新的一年，用户认知是OKR里的重点工作。

同在13日，腾讯让旗下AI大模型腾讯元宝接入满血版DeepSeek R1 671B，同时可选深度思考和联网搜索，剑指用户流量。与DeepSeek本尊相比，明显“不卡了”。

从技术军备竞赛到用户入口争夺，大模型厂商的战略重心正发生根本性转向。

当推理成本以每年90%的速度下降，免费开放核心能力成为头部玩家的必然选择——通过零门槛接入快速占领开发者生态，在应用层爆发前构建用户护城河。

而中小厂商或将面临“用不起算力，留不住客户”的双重困境。

#### “免费即标配”

DeepSeek将单次推理成本降至可忽略水平，大模型从技术制高点转变为基础设施，免费策略成为吸引用户、建立生态的必经之路。

快思慢想研究院院长、原商汤智能产业研究创始院长田丰认为，当前DeepSeek具有很强的复杂任务推理能力，又具备联网搜索能力，搜索深度能达到50个相关网页，所以免费版DeepSeek不仅在抢其他to C大模型App的用户，还在抢搜索引擎的用户与广告流量。

百度此次宣布全面免费，或许意在“找回”用户。作为最早一批面向市场的AI大模型，没有人能够否认文心一言拿到了第一批国人的AI心智。但随着Kimi、豆包、DeepSeek等后起之秀轮番上场，属于文心一言的活跃用户，也在重新流向市场。

OpenAI也难置身事外。DeepSeek让奥特曼首次承认OpenAI的闭源策略站在了历史的错误一边，C端用户对DeepSeek的追捧，让这家AI巨头也开始担忧起“AI入口”的地位是否能保持。

如今，奥特曼把“期货”都拿出来了，提前宣布，未来即将发布的GPT-5允许免费用户在标准智能设置下无限制使用。同时为了留住付费群体，Plus和Pro用户可以调用“高智能水平”和“更高智能水平”的功能。

这些业务举措，本质上是对用户入口的焦土式争夺。

与此同时，中小厂商的生存显得愈发艰难。

算力成本对长尾厂商而言，是非常沉重的负担。虽然训练大模型的成本已经有明显下降，但免费策略将迫使企业每日承担数百万次推理的沉没成本。

跟进免费，经济账算不过来；不跟进免费，几乎等同于断了发展的路。

“C端用户一向喜爱在免费的AI模型中选择领先性最好的。”田丰说，当免费成为标配，留给to C通用大模型中小厂商的时间不多了。

#### 大模型价格战再升级

正是DeepSeek开启了大模型价格战，并不断推向高潮。

DeepSeek V2模型于2024年5月发布，API定价为每百万tokens输入1元、输出2元（32K上下文），仅为OpenAI GPT-4 Turbo价格的约1%（输入价格仅为GPT-4 Turbo的1/70至1/35）。

这种“价格屠夫”策略直接打破了行业原有的定价体系，掀起了巨浪。例如，GPT-4 Turbo的定价为输入每百万tokens约70元，而DeepSeek-V2仅需1元，性价比优势显著。

当年5月，百度迅速跟进，旗下文心大模型两款主力模型ERNIE Speed和ERNIE Lite全面免费，并立即生效。阿里云紧随其后，将通义千问GPT-4级主力模型Qwen-Long的API输入价格从0.02元/千tokens降至0.0005元/千tokens，降幅达97%，价格仅为GPT-4的1/400。字节跳动则推出豆包大模型，其pro-32k版本定价0.0008元/千tokens，号称“比行业便宜99.3%”，相当于1元可处理284张720P的图片。

2024年底至2025年初，竞争继续升级。阿里云于1月1日宣布通义千问视觉理解模型全线降价超80%，Qwen-VL-Plus输入价格低至0.0015元/千tokens，称其为全网最低。

1月20日，DeepSeek-R1的API服务定价为每百万输入tokens 1元（缓存命中）/4元（缓存未命中），每百万输出tokens 16元（2月9日前的优惠期减半），这一价格远低于OpenAI o1的438元每百万输出tokens。

国际厂商亦被迫应战。OpenAI2024年5月发布的GPT-4o不仅性能提升，还允许免费使用基础功能，同时API调用价格较此前版本减半。在DeepSeek-V3和R1压力下，2025年2月6日，OpenAI发布的o3-mini模型，价格较前代降低63%。

“DeepSeek和其他各家AI基础模型企业，都在通过基础设施优化、工程化能力持续降低成本。”田丰表示，2025年会是大模型的“成本年”。

一位AI资深观察人士认为，免费即将成为大模型竞争常态的当下，厂商们需要探索新的盈利模式。比如增值服务、数据销售、广告投放等。通过为用户提供更多的价值，在其他领域实现商业价值的最大化。

#### 端侧应用初具爆发态势

价格战的底层驱动力是推理成本的大幅下降。

以文心大模型为例，其日均调用量从2023年的不足5000万次跃升至2024年的15亿次，规模效应显著摊薄单位成本。阿里云则通过自研芯片和算力优化，将通义千问长文本处理成本压缩至行业最低。

技术迭代也加速了降价进程。文心一言的深度搜索功能集成了多模态输入与专家级内容生成能力，可调用外部工具处理复杂任务，使其能够以更低成本覆盖更广泛场景。字节跳动的豆包模型则凭借火山引擎的高效算力调度，实现TPM（每分钟请求数）限额达到行业标准的2.7~8倍，进一步降低边际成本。

DeepSeek是这方面的极致代表，其两款模型训练成本仅为560万美元左右，约为OpenAI同类模型的十分之一，它通过优化算法采用MoE架构、多头潜在注意力（MLA）等技术，高效硬件利用，GPU集群使用效率远超行业平均水平，显著降低了算力需求。

短期看，成本下降催生了医疗、教育、创意等领域的应用浪潮；长期看，免费模式与多模态能力将重塑行业生态。

由DeepSeek引发的端侧AI应用热潮正席卷全球。

田丰表示，“DeepSeek时刻”带来了各行各业使用AI的“成本拐点”，开源意味着用户可以随意修改模型权重和训练过程，同时二次开发商还不需要License费用，这是全球开发者的创新机会。

“极低的推理成本、运营成本，会直接激活一大波AI应用创新浪潮。”田丰说，众人拾柴火焰高，国产大模型“操作系统”上将会涌现出超级AI应用，让用户规模、市场需求呈指数级上升。

与此同时，其他厂商也在扩大AI应用的规模化落地。数据显示，文心大模型在医疗、教育等垂直领域的AI Agent应用快速普及。阿里云和百度与教育、医疗机构合作，大幅提升了产业效率。

AI观察人士表示，一系列最新模型以低成本、高性能和跨场景兼容性，将推动AI技术从云端向终端设备渗透，重构软硬件生态，开启“端侧AI元年”。

#### 从芯片到应用的生态重构

DeepSeek以低成本高效率为特征的崛起，引发全球科技巨头竞相合作。

海外方面，英伟达、亚马逊、微软等已接入其API，英特尔已针对DeepSeek进行硬件优化，使开发者能以更低成本部署复杂任务；国内华为云、腾讯云、阿里云等头部云服务商，三大运营商，以及大批科技企业和上市公司，都已宣布加入生态。

DeepSeek的工程技术路线的创新和开源策略，带动了产业链上下游的爆发。

在硬件层，端侧AI芯片需求激增，国产芯片厂商迎来机遇。例如，华为昇腾系列芯片已适配DeepSeek模型，推动智能终端算力升级。

在软件层，边缘算力调度、模型轻量化工具等开发需求旺盛。IDC预测，预计中国的生成式AI软件市场规模2025年将达35.4亿美元。Omdia的报告称，未来五年，中国的GenAI软件收入将增长超过四倍。

在应用层，DeepSeek在C端掀起了一场声势浩大的AI科普浪潮，“你用DeepSeek了吗？”几乎成为一句问候语。

据高盛最近发布的《生成式AI Part X：在开源模型性能的背景下审视行业格局》报告测算，DeepSeek通过端云协同架构实现成本优化，可使企业运营成本降低30%，企业计算资源消耗平均降低40%以上，同时效率提升30%。

DeepSeek本地化部署避免敏感数据上传云端，符合医疗、金融等行业的合规要求。未来，AI Agent可望在智能制造、智慧医疗、金融风控等领域加速落地。在自动驾驶、工业质检等场景，端侧推理延迟降至毫秒级，较云端方案提升5倍。

田丰向21世纪经济报道记者表示，DeepSeek通过领先性能、低成本、开源、快速迭代等特点，加速中国互联网应用、传统软件应用、人机协同服务、具身智能等实现规模化落地。全球开发者逐步向中国开源大模型技术社区聚集，并贡献源代码和创新产品服务。

随着AI应用在2025年进入爆发期，一场由终端重塑引发的生态重构正在拉开帷幕。

[qq](https://new.qq.com/rain/a/20250214A06HV700)
