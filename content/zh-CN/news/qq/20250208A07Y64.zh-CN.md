---
title: "我们问专家怎么看DeepSeek？专家：等我问问DeepSeek"
date: "2025-02-08 20:06:09"
summary: "在全球AI竞赛白热化的今天，中国杭州的深度求索人工智能基础技术研究有限公司的DeepSeek大模型以..."
categories:
  - "qq"
lang:
  - "zh-CN"
translations:
  - "zh-CN"
tags:
  - "qq"
menu: ""
thumbnail: "https://inews.gtimg.com/om_ls/OWnRw5QixAoL7YmZQaBht7pldNO5UIIoSDMojpua76AL8AA_640360/0"
lead: ""
comments: false
authorbox: false
pager: true
toc: false
mathjax: false
sidebar: "right"
widgets:
  - "search"
  - "recent"
  - "taglist"
---

在全球AI竞赛白热化的今天，中国杭州的深度求索人工智能基础技术研究有限公司的DeepSeek大模型以“低成本、高效能、开源性”技术标签，成为搅动全球AI行业格局的关键力量。

DeepSeek发布以来，不仅在全球开源模型的性能测试中位列榜首，即使与最先进的OpenAI o1等闭源模型在性能上对标也不分伯仲，更关键是训练成本仅有OpenAI十分之一，性能上却能实现90%以上对标，甚至在数学推理、代码生成等垂直任务中超越国际顶尖闭源模型。

![图片](https://inews.gtimg.com/om_bt/OOBppOJtnXxHarx8esPwYQB0L1t0dk-Gr0_0MFBOnr8YsAA/641)

这一突破背后究竟隐藏着怎样的技术创新逻辑？低成本与高效能又是如何兼得？这对全球AI产业将带来哪些深远影响？近日，中国人工智能学会机器博弈专委会主任、重庆理工大学教授张小川接受上游新闻记者采访时，将这些问题输入DeepSeek，通过人与AI共创的形式，解读其底层技术密码。

**提问：为什么说DeepSeek的计算架构是一次混合架构革命？**

**DeepSeek：**传统大模型基本都采用谷歌Transformer计算架构，其对算力、电力、时间的消耗极其惊人；而DeepSeek创造性采用可扩展的混合专家系统（Scalable MoE），使用动态专家路由算法与稀疏计算深度融合的创新架构。简单来讲，DeepSeek自建专家小组，从而提升效率并降低能耗。例如，面对“今天星期几？”这样简单问题，实际上大模型仅需极少算力支持即可，只有面对求解“DeepSeek对全球AI将带来哪些深远影响”复杂问题时，才需动用大算力支持。这时，DeepSeek可以自动建立逻辑推理、法规检索、语义分析等临时性专家组及其任务链，不再调用其它算力。这种灵活架构使模型效能得到极大提升。

DeepSeek独创多层级“教师-学生模型”协作框架的知识传承“知识蒸馏”新机制，实现了实时动态关闭无关的模型参数，将万亿参数模型的知识密度有效迁移至千亿级模型。这种分布式计算架构，既建立了高效的负载均衡策略，将计算任务分散到多节点且并行处理，这样既加快了训练速度，又降低了单节点计算负担及其对单一芯片高性能的依赖，并采用高效压缩算法压缩数据，从而显著减少数据存储、传输的压力。这样就能显著降低对高性能芯片、大容量存储器和超带宽传输的依赖程度，进一步压缩了训练和使用成本。

**张小川：**大模型学习能力生长过程有点类似学校的知识传承，不同学校、不同老师会有不同的传承方法。DeepSeek设计了“以大教小”知识传承机制，这犹如使用知识、经验更丰富的教师（大模型）来训练学生（专家模型）一样，构建了多层级“师-生模型”协作框架，将万亿参数模型的知识密度有效迁移至千亿级模型。在南京大学联合实验室测试中，这种模式运作下的知识保留率达到98.7%，证明了该机制的知识传承效率极高。

**提问：从“堆芯片”到“拼效率”，DeepSeek如何实现算力成本控制？**

**DeepSeek：**面对只能使用性能受限的阉割版芯片现状，DeepSeek难能可贵的不是简单使用英伟达芯片及其CUDA技术，而是深入到硬件指令层，进行重构和优化。比如，并没有使用其他大企业所使用的FP16技术，而是使用基于8位浮点数的FP8混合精度训练技术，尽管训练精度较低，但是能够大幅降低训练成本和降低对GPU显存的占用，从而极大提高训练速度。这种建立在系统视角的优选方案，即使是使用了位数更少的浮点数来训练模型，却能在效果提升、成本降低上达到最优，这就是在大模型前沿探索的方向性引领与应用示范。

DeepSeek团队通过三项关键技术，突破了训练成本瓶颈：一是异构计算感知的分布式框架，通过自动识别GPU/TPU/国产芯片特性，动态分配计算任务，使千卡集群利用率从行业平均50%提升至85%；二是智能数据引擎，基于强化学习的训练样本筛选系统，仅用30%的数据量即可达到全量数据90%的模型效果；三是渐进式课程学习，通过模仿人类学习曲线，先学习高频简单模式，再攻克长尾复杂案例，训练周期缩短40%。此外，DeepSeek还创新了自监督数据增强技术，模拟人类联想机制，自动生成高质量合成数据，实现AI训练AI，极大降低了对数据标注需求，且保证了训练性能。

**张小川：**由美国引领的大模型领域，一直鼓吹大模型是大算力、大数据的“烧钱”竞争，为限制他国发展，制定了严格的“护城河”，我国自然成为其优先针对国家。因此，我们需要创立新赛道，打破美国“垒芯片”“堆算力”传统赛道，建立“拼效率”等新赛道。DeepSeek正是这样做的，并在最短时间内，以极低投入获得了性能上可对标国际上最先进的大模型。

**提问：DeepSeek促进AI基础设施重构的重大价值是什么？**

**DeepSeek：**DeepSeek的低成本、高性能、开源策略，极大降低AI技术的应用门槛，推动大模型转化为人人能用的“工具”。通过算法-架构-训练的全栈优化，DeepSeek使百亿参数模型的训练成本降低60%，推理延迟控制在毫秒级。更让外界意想不到的是，DeepSeek居然推出模型即服务（MaaS）和代码开源，允许按需付费调用API，而且支持私有化部署，开源多个轻量化模型，推出行业定制平台，支持客户3天内完成垂直领域模型的微调部署等等。如东莞某制造企业利用该MaaS，仅仅2周时间就开发出智能质检系统，将缺陷识别准确率从人工巡检的85%提至99.5%，投入成本不足传统方案十分之一。再如某云计算平台部署深度求索后，训练百亿参数模型的综合成本从行业平均300万美元降至80万美元等。显然，这种开放战略，正推动AI技术从集中化走向分布式创新，必将打破大模型应用壁垒，让全球的众多中小企业享受AI红利。

**张小川：**AI基础设施重构将更深远地影响产业标准的话语权争夺。目前DeepSeek主导的高效计算协议标准，已获全球50余家芯片厂商支持，这可能改变英伟达在CUDA生态的垄断地位。DeepSeek坚持模型开源并API开放策略，开发者可定制、优化，让更多人参与AI创新，加速全球AI技术协作及其丰富技术生态的形成，促进全球AI产业布局的多元化，提升中国AI产业全球竞争力。

**对话：大模型普及后，全球面临新挑战**

张小川在接受上游新闻记者采访时表示，当DeepSeek等公司推动大模型的应用开发成本降至“白菜价”后，滥用大模型的风险指数就将急剧上升。尽管DeepSeek建立了区块链、数字水印、内容溯源等治理工具，但如何在全球范围内构建协同治理机制，仍是亟待破解的难题。

人人可用、人人会用大模型，必将给人们学习、工作、生活带来便利的同时，产生不可避免的负面影响。如对正处于求学阶段的在校学生，本应该构建各种基础能力底座、培养基本技能，而科学便利地借用大模型完成作业、代码、论文等，势必产生学生能力“惰化”，这对全体教育工作者、家长提出全新挑战。

总之，这场由中国人主导的技术革命，正在改写AI发展的底层逻辑。当模型效率提升的速度超越摩尔定律，当每个开发者都能负担起智能时代的入场券，我们迎来的或许不仅是技术的进化，更是整个人类学习方式、社会认知范式、科研范式的颠覆。可以预见，随着通用人工智能AGI的到来，让AI如水电般渗透到人们生活、学习、工作、娱乐的各个角落，任何闭源形成的“护城河”，在颠覆性技术面前都是短暂的。

上游新闻记者 吴嘉雯

[qq](https://new.qq.com/rain/a/20250208A07Y6400)
