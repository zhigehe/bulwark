---
title: "豆包新模型VideoWorld无需依赖语言、仅通过“视觉信息”认知世界"
date: "2025-02-10 15:51:09"
summary: "2月10日，界面新闻获悉，豆包大模型团队联合北京交通大学、中国科学技术大学共同开发的视频生成实验模型..."
categories:
  - "qq"
lang:
  - "zh-CN"
translations:
  - "zh-CN"
tags:
  - "qq"
menu: ""
thumbnail: ""
lead: ""
comments: false
authorbox: false
pager: true
toc: false
mathjax: false
sidebar: "right"
widgets:
  - "search"
  - "recent"
  - "taglist"
---

2月10日，界面新闻获悉，豆包大模型团队联合北京交通大学、中国科学技术大学共同开发的视频生成实验模型“VideoWorld”正式开源。

不同于主流多模态模型，VideoWorld 在业界首次实现无需依赖语言模型，即可认知世界。这一创新，也是在人工智能视频生成和多模态认知方面取得的重要突破。

传统的多模态模型，如Sora、DALL-E和Midjourney等，大多依赖于语言或标签数据来学习知识，而VideoWorld则通过纯视觉信号进行学习和推理。这一特性使得VideoWorld在处理如折纸、打领结等难以通过语言清晰表达的任务时，具有显著优势。

大模型的视觉理解能力一直是AI前沿研究方向之一。视频中存在大量冗余信息，会影响模型的学习效率，使得视频序列的知识挖掘效率显著落后于文本形式。但李飞飞教授曾在TED演讲中提到，“幼儿可以不依靠语言理解真实世界”。与语言相比，“用眼睛看”是人类门槛更低的认知方式。

据介绍，VideoWorld的核心技术基于一种潜在动态模型（LDM），该模型能够高效压缩视频帧间的变化信息，显著提升知识学习的效率和效果。

此外，VideoWorld还结合了自回归Transformer架构和矢量量化-变分自编码器（VQ-VAE），实现了高质量的视频生成和复杂的任务推理。通过这一组合，VideoWorld能够从未标注的视频数据中学习复杂的任务知识，包括规则、推理和规划能力。

在实际应用中，在不依赖任何强化学习搜索或奖励函数机制前提下，VideoWorld 达到了专业 5 段 9x9 围棋水平，能够选择最佳落子位置并击败高水平的对手。

此外，该模型还具有扩展到自动驾驶、智能监控等领域的潜力。

VideoWorld的开源项目代码和模型已公开发布，豆包大模型团队也提供了详细的安装和运行指南。

2月10日，受此消息影响，A股视觉认知概念股午后大幅走强，创业板星宸科技直线拉升涨停，全志科技、富瀚微、虹软科技等纷纷大幅冲高。

[qq](https://new.qq.com/rain/a/20250210A05AST00)
