---
title: "CEO采用AI必须理解一件事，否则将会付出代价"
date: "2025-02-08 21:01:46"
summary: "萨姆·奥尔特曼最近宣称，OpenAI已经知道如何构建通用人工智能（AGI），这再次引发了有关AI未来..."
categories:
  - "qq"
lang:
  - "zh-CN"
translations:
  - "zh-CN"
tags:
  - "qq"
menu: ""
thumbnail: "https://inews.gtimg.com/om_ls/OqSH0SM5N9YTZFCL2xdXuqmy9VnGOvRtAXwnTMG46_0GcAA_640360/0"
lead: ""
comments: false
authorbox: false
pager: true
toc: false
mathjax: false
sidebar: "right"
widgets:
  - "search"
  - "recent"
  - "taglist"
---

![图片](https://inews.gtimg.com/om_bt/OsPsIjnGqsZUyZmK-txJWe-StppAnj7cJ3PM529-tQwUcAA/641)  

  


萨姆·奥尔特曼最近宣称，OpenAI已经知道如何构建通用人工智能（AGI），这再次引发了有关AI未来的辩论。虽然这些主张频频登上媒体头条，但作为一名研究人脑工作原理超过十年的神经科学家，我发现自己关注的是一个不同的悖论：对现代AI系统最常见的批评之一是我们没有完全理解它们的工作原理，这实际上可能是它们最像人脑的特征之一。  


  


当前的AI热潮导致对AGI有各种模糊的定义。但从神经科学的角度来看待AI，为我们提供了宝贵的机会，对AI的能力和局限性进行有意义的现实检验。  


  


现实是，尽管经过了几个世纪的科学探究，我们仍然没有完全了解人类大脑的工作机制。作为研究人员，我们可以观察到某些神经元执行特定功能，但关于我们的认知过程实际上如何执行，这种知识的解释能力极其有限。然而，这并没有阻止我们成为有生产能力的社会成员或者做出重要的决策。  


  


同样，我们理解AI背后的数学原理，但在相对简单的数学运算和这些系统表现出的非凡智能之间存在着神奇的飞跃。这种生物神经网络和人工神经网络之间的相似性不是缺陷，而是复杂智能系统的标志。  


  


以我和朋友最近使用OpenAI o1（目前最先进的 AI 模型之一）的经历为例。我们向它展示了一个由不同州的车牌拼接而成的视觉谜题，并要求它识别每个字母或数字来自哪个州。经过几分钟的思考，它提供了一段清晰流畅而自信的分析，但结果几乎完全错误。  


  


即使在收到详细反馈之后，它又生成了一个自信但同样错误的答案。这暴露出AI的一个关键局限性：尽管当前的AI在许多领域表现出色，但它可能缺乏自我意识，无法识别它可能出错的情况，而这是人类智能的一个宝贵元素。  


  


**商业意义**

  


这揭示了一个关于智能的更广泛的真相：智能不是一种单一的能力，而是一系列专门学习系统的组合。人脑有不同的机制——从语义记忆（如知道2+2=4的事实知识）到回忆个人体验的情景记忆（如记住你第一次学习算术的时刻），以及隐性概率学习（如在不自觉理解原因的情况下提高网球水平）。尽管AI基准测试变得越来越全面和严格，但它们仍未能捕捉到人类智能的全部多样性。  


  


对于商业领袖而言，这具有重要意义。当前的AI浪潮并不是要全面取代人类智能，而是要理解这些工具可以在哪些方面补充人类的能力——以及在哪些方面无法作为补充。例如，在创意领域，生成式AI尚无法生成比人类专业人士更好的图像或视频。它是一种需要人类监督的“人机协同”工具。  


  


随着AI能力的增长，这种理解变得日益重要。特斯拉（Tesla）的自动驾驶技术展示了其未来前景和风险：尽管它可能在99.9%的时间内表现出色，但人类往往难以辨别99.9%和99.9999%准确率之间的差异。因此，我们可能对其产生一种过度的信任，忽视了小数点后增加几位数对于确保真正安全的重要性。偶尔出现的不可预测的故障会提醒人们，这些系统尚未完全符合人类预期的复杂性和现实世界的不可预测性。  


  


**人工智能的局限性**

  


虽然机器在长期记忆和处理速度方面早已超越了人类的能力，现在在其他领域似乎也将超越人类，但相比一些行业领导者的观点，全面复制人类的智能仍然是一个更遥不可及的目标。值得注意的是，大多数AI基准测试将机器性能与人类个体进行比较。然而，人类通常不是孤立的。从建立文明到解码人类基因组，人类最重要的成就都是集体努力和合作的产物。共享知识、团队合作和文化传递的专业知识使我们能够突破个人的局限性。因此，虽然AI模型可能在某些任务上优于人类个体，但它并不能复制一群人共同工作时所产生的那种协同智能。这种由语言、文化和社会互动推动的动态、集体问题解决能力是人类智能的一个关键方面，当前的AI系统并不完全具备这种能力。  


  


理解这种更细微的现实，对于公司高管应用AI至关重要。我们不能局限于AI是否达到了人类智能水平这个二元问题，而是应该专注于理解AI系统在具体维度上的优势和劣势。成功采用AI的关键不是盲目信任或全面怀疑，而是要细致地理解这些系统的能力和局限性。正如我们在不完全理解人类智能的情况下学会了高效利用人类智能一样，我们需要开发与人工智能合作的框架，既承认其非凡的能力，也承认其固有的不可预测性。  


  


这并不意味着要放慢开发AI的速度，其实AI的进开发展令人惊叹，值得庆祝。但随着这些系统变得越来越复杂，且对AGI的辩论仍在继续，我们就需要保持一种平衡的观点，既认识到它们的变革潜力，也认识到它们的基本局限性。AI的未来不是实现完美的理解或控制，而是学会如何与这些系统有效合作，这些系统可能像我们自己的大脑一样，总是保留着某种神秘元素。（财富中文网）  


  


译者：刘进龙  


  


审校：汪皓

[qq](https://new.qq.com/rain/a/20250208A08E8Q00)
