---
title: "今天，百度OpenAI对普通用户免费！DeepSeek的API已涨价"
date: "2025-02-13 19:47:22"
summary: "新一轮大模型算力价格战，一触即发！作者／  IT时报记者  毛宇编辑／  郝俊慧  孙妍DeepSe..."
categories:
  - "qq"
lang:
  - "zh-CN"
translations:
  - "zh-CN"
tags:
  - "qq"
menu: ""
thumbnail: "https://inews.gtimg.com/om_ls/O36oyyO7lhsoaZOucBNoWMO1hT3IlsACS9jGLqVZ8q8YkAA_640360/0"
lead: ""
comments: false
authorbox: false
pager: true
toc: false
mathjax: false
sidebar: "right"
widgets:
  - "search"
  - "recent"
  - "taglist"
---

![图片](https://inews.gtimg.com/om_bt/OG6f_QDCQ_JY5x10vBfhWQQ5b-5M3bXr69Dqwrr0ofMdMAA/641)

**新一轮大模型算力价格战，一触即发！**

**作者／  IT时报记者  毛宇**

**编辑／  郝俊慧  孙妍**

DeepSeek的“鲶鱼效应”正在加速。

  


2月13日，文心一言宣布，4月1日起全面免费，同时上线深度搜索功能。此前，百度基于文心一言 4.0 Turbo推出的专业版会员服务定价为59.9元/月。

![图片](https://inews.gtimg.com/om_bt/OtBmMqC4EmlPVGVXvEjPh7bnVfy9NbXrZy8DGkLbOqA7gAA/641)

同日，OpenAI宣布GPT-4.5和GPT-5路线图更新、模型规范重大更新，并预告GPT-4.5和GPT-5将在几周/几个月内推出，更重要的是，ChatGPT的免费套餐将在标准智能设置下获得对GPT-5的无限制聊天访问权限。

  


不过，对于业内更为关注的API（应用程序编程接口）服务费用，百度和OpenAI却没有给出更多信息，当C端用户可以免费获得越来越好的AI服务时，开发者们更希望大模型的算力价格战来得更猛烈些。

  


2月9日，DeepSeek-V3宣布，结束API服务45天优惠期，价格回调至原价，输入每百万Token收费0.5元（缓存命中）至2元（缓存未命中），输出价格则定为每百万Token 8元，是优惠期的4倍。

  


不过，在业内人士看来，这个价格“仍然是高性价比”，尽管从2024年5月开始，国内各大模型厂商先后展开多轮价格战，但在开发者看来，只是“噱头更足”，因为性能强大的高阶模型“还是很贵”，DeepSeek的算法架构创新和分布式训练优化等创新，才真正将价格打下来。

  


新一轮的大模型价格战，箭在弦上。有分析指出，这场由算法突破驱动的价格革命，可能重塑全球AI服务市场格局，加速市场洗牌进程。

  


价格更为敏感的算力市场已暗流涌动，山海引擎COO彭璐告诉《IT时报》记者，国内企业都已经在加快提升国产算力部署规模，其中华为昇腾、寒武纪、摩尔线程等国产GPU产品需求显著上升。不过，基于“DeepSeek的低成本能力，预计数据中心的算力价格不会上涨”。

![](https://inews.gtimg.com/om_bt/OOu7pHeHyzWElma6IVVt0u6r9P8PVEQu14Ul0kZ4xzq18AA/641)

**创新诞生“AI界拼多多”**

DeepSeek被称为“AI界的拼多多”是有道理的。

  


目前，OpenAI GPT-4o API服务定价为每百万输入Token 1.25美元（缓存命中）（约9.13元人民币）/ 2.5美元（缓存未命中）（约18.27元人民币），每百万输出Token 10美元（约73.091元人民币），而Claude 3.5-Sonnet依然是最昂贵的模型，价格高出DeepSeek-V3数倍。

![图片](https://inews.gtimg.com/om_bt/O9dm1ALUpGZx7C1Cq1Za5OofoDmTh0iWFEVOupydcogusAA/641)

即便是DeepSeek推理能力更强、性能比肩OpenAI o1正式版的R1模型，每百万输入Token 1元（缓存命中）/4元（缓存未命中），每百万输出Token 16元的API服务价格，也几乎是OpenAI o1同等规模输入15美元（约109元人民币）和输出60美元（约437元人民币）的二十分之一到百分之一。

  


国内大模型企业从2024年5月进入降价周期，通义、豆包、Kimi、百度的降幅大多在80%以上，但当去年12月DeepSeek发布V3时，尤其是在45天优惠期内，价格非常香。

  


“DeepSeek的低价源自成本够低。”上述AI业内人士表示，DeepSeek采用的MOE模型架构并不很新，MiniMax等国内厂商也早已开始应用，但DeepSeek-V3引入了多头潜在注意力机制，通过低秩压缩技术减少了推理时的Key-Value缓存，显著提升了推理效率，此外，DeepSeek-R1在做训练时，跳过了传统训练中的监督微调（SFT）步骤，使用了RL强化学习的方法，完全依赖环境反馈来优化模型行为，同样省去很多算力成本。

![](https://inews.gtimg.com/om_bt/O2mQ2V2XXD1qzKITTybxw8hhbyCr0cl-txCzIOQ72ubs8AA/641)

**大模型算力价格有望普降**

没让大家失望，“AI界拼多多”果然将价格打下来了。由于DeepSeek完全采用开源模式，这些技术创新正在被全球人工智能产业学习并复刻，大模型算力价格有望迎来一次普降。

  


短短一个多月过去，DeepSeek横空出世带来的“鲶鱼效应”明显。据《IT时报》记者观察，截至目前，已有多家国产大模型厂商推出新的性能比肩DeepSeek-V3的产品，加上优惠期结束，V3已不是绝对的“性价比之王”。

  


同样走开源路线的阿里云大模型通义，在2月4日三方基准测试平台ChatbotArena公布的最新大模型盲测榜单上，以刚刚发布的Qwen2.5-Max超越DeepSeek V3、o1-mini和Claude-3.5-Sonnet等模型，成为非推理类的中国大模型冠军。目前Qwen2.5-Max的API调用价格还未公布，而在2024年9月发布的价格表上，通义的上一代旗舰模型、性能逼近 GPT-4o的Qwen-Max每百万Token输入成本为2.4元，输出成本为每百万Token9.6元，略高于DeepSeek-V3。

![图片](https://inews.gtimg.com/om_bt/Oy0n6uLzoJNHvLuDrsWE0hkPK1Z03DLFMse_q882sUuqkAA/641)

另一家国内AI创业公司MiniMax（稀宇）也于1月15日推出MiniMax-Text-01，基准测试结果显示，性能比肩GPT-4o和Claude-3.5，价格为输入每百万Token0.2美元（1.45元人民币），输出每百万Token1.1美元（8元人民币），和DeepSeek-V3几乎持平。

  


当然，也有分析人士指出，虽然价格较高，但闭源大模型OpenAI GPT-4o和Claude 3.5-Sonnet在多模态、泛化能力以及综合能力上的优势依然存在，不少开发者暂时还不会放弃。

![](https://inews.gtimg.com/om_bt/OUlBZCiIcjcLEqDi8PrghZPvbxOMxvJjpzl9sztzn2JzwAA/641)

**英伟达模组出现低价抛售**

同时，随着DeepSeek开源模型的广泛应用，国产GPU服务商迎来新一轮增长机遇，算力市场格局也正经历深刻变革。

  


一名算力厂商工作人员告诉《IT时报》记者，目前国产GPU相较英伟达更受市场青睐，华为昇腾、寒武纪、摩尔线程等国产GPU需求显著上升，部分企业开始转向国产芯片进行模型推理和微调，但价格还算平稳，没有明显变化。

  


当下，国内多数企业都在自行部署DeepSeek。其中DeepSeek满血版模型对显存要求较高，需要1.25台H100或1台H200支持，但4位量化版仅需400GB左右的显存。上述人士透露，有客户已经在国产GPU服务器上做本地化部署的适配，从成本上来说，虽然仍需数万元，但较之前已大幅降低。

  


据了解，目前亚马逊和阿里云平台已有服务商在低价抛售H100模组，上述人士分析，此前生成式AI大模型厂商选择英伟达，是因为其成熟的CUDA生态和GPU的通用能力，也是当时性价比最高的方案，因此大厂争相堆砌算力资源。“小力同样也能出奇迹”的DeepSeek靠算法突破算力限制，且客户需求逐渐向推理和微调转移，国产GPU适配性正在提升，从而挤压了英伟达的部分市场空间。

  


DeepSeek的API商业化，本质上是一场深刻的“技术效能革命”。彭璐认为，DeepSeek的出现，推动算力市场开始思考如何从“堆算力”转向“精细化运营”，企业更注重单位算力的效能，市场供需平衡正在重构。同时，DeepSeek的开源策略也降低了AI应用的门槛，未来入局AI赛道的中小企业或会大幅增加。

排版／ 季嘉颖

图片／ ChatbotArena  豆包AI  百度 网络  

来源／《IT时报》公众号vittimes

[qq](https://new.qq.com/rain/a/20250213A083A600)
