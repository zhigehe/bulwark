---
title: "突破英伟达封锁、打破李彦宏断言，DeepSeek凭什么逆袭？"
date: "2025-02-10 16:47:01"
summary: "如果你在年前刚买了英伟达的股票，那么这个春节或许会过得不太开心，自从DeepSeek在1月20日正式..."
categories:
  - "qq"
lang:
  - "zh-CN"
translations:
  - "zh-CN"
tags:
  - "qq"
menu: ""
thumbnail: "https://inews.gtimg.com/om_ls/OnC-2k5_ktDa2kRj_NWN9OUw_UjNjt972Z3FejWHr4u-UAA_640360/0"
lead: ""
comments: false
authorbox: false
pager: true
toc: false
mathjax: false
sidebar: "right"
widgets:
  - "search"
  - "recent"
  - "taglist"
---

![图片](https://inews.gtimg.com/news_bt/Owrr5oRxyf2LYiJ3YdsL9N5GDZhT8djMY7nLOOXyx0tMUAA/1000)

如果你在年前刚买了英伟达的股票，那么这个春节或许会过得不太开心，自从DeepSeek在1月20日正式发布DeepSeek-R1模型并开源后，英伟达的股价就在除夕节的前一天来了一次“自由落体”，从148美元的高位一度跌到116美元。

![图片](https://inews.gtimg.com/news_bt/OMHVjgFp80UdS-DXluxwILwwgTnvgyBe-rb-M9Hn64z-UAA/641)

图源：百度

 

很多报道都将英伟达的股价暴跌归咎于“AI界拼多多”DeepSeek-R1模型，这倒也没错，因为DeepSeek-R1以一种“蛮横”的方式，打破了英伟达在AI算力层面的垄断。**不过，有人将其理解为DeepSeek-R1“不需要”英伟达显卡，这显然是错误的，毕竟DeepSeek-R1的训练服务器用的也是英伟达计算卡，并不是和英伟达彻底割席。**

 

其中的关键在于DeepSeek-R1是一个开源模型，采取的“蒸馏模型”对算力要求锐减，且不硬性绑定英伟达显卡。在摆脱英伟达硬件束缚的情况下，仍然在推理性能等方面都表现出与ChatGPT-o1接近的能力，部分领域还有所超越。

 

简而言之，DeepSeek让英伟达的高算力显卡不再是AI的“必选项”，这相当于给整个AI产业特别是中国AI产业注入了一剂强心针。但这对英伟达而言确实算不上是好消息，因为英伟达的高利润，恰恰来源于AI生态的“割裂性”。

 

**别名“CloseAI”，OpenAI从来都不Open**
==============================

OpenAI的地位毋庸置疑，作为最早被广泛认知的AI大模型企业，ChatGPT依然是顶流，并且也是所有AI大模型的对标基准。不过，虽然名字叫OpenAI，但是ChatGPT却一点也不“Open”，甚至是对用户使用限制最严格的AI之一。

 

比如，前段时间OpenAI就指责DeepSeek使用ChatGPT的数据进行模型“蒸馏”，违反了用户使用条例里的相关规定，不过最终因为没有证据，相关争议不了了之。OpenAI CEO对外表示并没有起诉DeepSeek的计划，并直言DeepSeek做得很棒。

![图片](https://inews.gtimg.com/news_bt/Ogkai0BSSIYnaUoeLNOjQLkVpvz55LXR23brDW3FKwWGwAA/1000)

图源：维基百科

 

**DeepSeek引发的AI行业震动，也在让OpenAI重新审视自己的AI模型开放策略，并重新评估开源模型的可能。**

这对英伟达的打击是致命的：ChatGPT几乎就是与英伟达AI生态深度绑定的代名词，你甚至可将其称为英伟达CUDA生态的基石。

 

微软等OpenAI的金主一直希望OpenAI可适配更多类型的显卡，然而到目前为止，其只是适配了部分AMD显卡，而且还需要通过转译等方式来运行，效率和性能表现都远不如直接用英伟达的显卡来运行。

 

CUDA+ChatGPT，实质上组成了一个封闭式的AI生态，这让需要顶级AI支持的企业不得不选择与OpenAI及英伟达合作。在OpenAI的带动下，Claude、Gemini等AI大模型几乎都与英伟达深度绑定。英伟达除了拥有性能遥遥领先的算力卡，CUDA完善的生态和开发工具链也是吸引AI开发者的法宝。

咋看下来，AI似乎以封闭为主？实则不然，诸如AMD的ROCm、Khronos Group的OpenCL等AI生态反而走的都是开源形式。毕竟在CUDA生态占优的情况下，其他生态只能通过开源来增加自己的盟友。

**DeepSeek才是OpenSeek，开源赢了？**
============================

日光之下没有新事。

当年PC产业，微软与Intel联合制霸，组建了沿袭多年的“Win-Tel”联盟，Windows生态负责消耗Intel的算力，Intel不断升级制程推动PC生态成熟与普及。历史上甚至留下了“安迪比尔定律”这样的名场面总结，也就是“Andy gives, Bill takes away”（安迪提供什么，比尔拿走什么），安迪·格鲁夫作为英特尔的CEO，致力于提升硬件性能，而比尔·盖茨则通过微软的操作系统和应用程序不断消耗这些性能，推动用户不断升级硬件。

两个巨头，赚得钵满盆满；余下玩家，跟着喝汤。在Win-Tel封闭联盟下，Unix、Linux等开源生态来吸纳盟友。

今天的AI计算格局，像极了PC发展历程。**AI大模型的生态日益割裂，OpenAI与英伟达等头部企业试图用封闭来确保领先，迫使后来者以开源来进行应对。几年来，开源生态都无法与CUDA的完整生态抗衡，时间上并没有一个可与ChatGPT抗衡的AI模型出现。**

2024年，百度CEO李彦宏甚至多次断言，“开源模型会越来越落后。”他的理由是，基础模型文心 4.0 可根据需要，兼顾效果、相应速度、推理成本等各种考虑，剪裁出适合各种场景的更小尺寸模型，并且支持精调和 post pretrain。这样通过降维剪裁出来的模型，比直接用开源模型调出来的模型，同等尺寸下，效果明显更好；同等效果下，成本明显更低。

对此，周鸿祎持反对意见，他认为“没有开源就没有 Linux、没有互联网，甚至包括我们自己借助了开源技术才能发展至今”。他还预言，在未来一到两年内，开源技术的力量很可能会超过闭源技术。

观点不重要，重要的是结果。横空出世的DeepSeek，证明了开源的力量——这里雷科技要PS一下（杠精勿杠）：DeepSeek不是代码开源，其只开源了部分推理代码和模型权重，完整的训练框架、系统代码、数据处理等都没有开源。**不过，行业公认它依然是开源路线下的AI产物，其开源程度足以让外界学习，给AI企业甚至AI巨头启发。**

 

**不是第一个开源的，为何DeepSeek赢了？**
==========================

在DeepSeek前，市场上并不缺少高质量的开源AI大模型，比如Meta的Llama、阿里的Qwen等，但是在高质量AI模型里，**只有DeepSeek选择了MIT+类OpenRAIL的授权方式进行开源。**

**![图片](https://inews.gtimg.com/news_bt/OItTCed0gpJy8Ay0wQRz1pxBySCUjEMWnDUXhZiqEfF2oAA/641)**

**图源：deepseek**

 

简单来说，DeepSeek允许第三方对其代码进行自由使用、修改、复制和分发代码，只要保留原作者的版权声明和许可证声明即可，这几乎是开源生态中最「Open」的协议。

目前DeepSeek开源社区已有多个开发者上传数十款不同显卡的算子库。简单来说，DeepSeek做好了一个底层，并搭好了一个基于英伟达显卡的基础模板，同时给出了基础版的异构部署方案，「舞台搭好了，现在请各位开始你们的表演」。

 

在MIT开源协议的基础上，第三方可根据需要随意修改DeepSeek的运行代码，使其适配不同的硬件设备，这是DeepSeek-R1普及的第一个撒手锏（关于DeepSeek如何重新定义AI硬件掀起“DeepSeek硬件”潮流，雷科技已进行系列分析和报道，欢迎全网搜索查看）。

第二个撒手锏则是跨平台的API封装，如果你研究过DeepSeek-R1的部署代码，会发现**DeepSeek将CUDA、ROCm、OpenCL等底层指令都封装为统一接口，这意味着开发者无需修改代码就可在不同的AI硬件之间迁移模型。**

 

为了更好地适配不同硬件生态，DeepSeek从底层开始对AI大模型和代码进行优化，**并引入了即时编译技术，让AI模型可根据显卡类型动态生成最优计算图，使得不同的计算设备，都可高效运行DeepSeek模型。**

看起来似乎并不难，为什么此前没有其他AI企业尝试使用即时编译技术，实现广泛的硬件适配呢？原因出在代码上。DeepSeek为解决H800显卡性能不足以及跨芯片通信的瓶颈问题，最终选择绕过CUDA和C/C++，从更底层的PTX开始编码。

 

你可以将PTX理解为一种接近汇编语言的玩意。开发者可通过PTX编写指令，直接调动硬件来运行AI。**PTX虽是英伟达AI生态的一部分，但是并不针对特定的GPU运行，因此将其转译为其他硬件平台的指令后会远比以往更高效和方便。**

**![图片](https://inews.gtimg.com/news_bt/OzHP3TFYRkUl8P6dlKmvk0xHVLZvWnm6MlF7_wnqD3LBsAA/641)**

**图源：Codeplay**

 

简单地说，你可以将AI理解为一个项目组：用户是公司的CEO，CUDA是项目组的管理人员，PTX是组员（实际上有更底层的干活人员）。在正常的流程中，你想执行一个项目，需要先告诉CUDA你的需求，然后CUDA将其分解成不同的工作内容再转给PTX让“组员”执行，这时候你的公司效率就取决于CUDA的数量与能力。

 

DeepSeek则制定了一个新的工作流程：你可与PTX更扁平地沟通，将工作直接分配到干活的人，相当于越过其中一个步骤，对整个流程进行提效。从DeepSeek公布的论文来看，他们成功地将流处理器（CUDA）的寄存器使用率从78%提升至92%、计算单元闲置时间减少40%、全局内存访问延迟从600周期降至450周期，从而实现了算力效率的暴涨和算力成本的暴跌。

 

在更基础的代码系统支持下，**DeepSeek的AI模型在转译时也拥有更高的效率，并且可在一定程度上绕开CUDA的限制，进而适配不同的硬件**。实际上，已有很多人通过CPU来复现DeepSeek的AI模型部署，借助虚拟显存等技术，将内存转为显存，利用核显算力来驱动模型，极大地降低了AI大模型的部署门槛和成本。

 

DeepSeek的创新还有许许多多，比如混合显卡集群调度算法的优化、边缘设备适配优化、梯度累积显存压缩等一系列技术，使其可以更好地适配多显卡系统。

前几天小雷在朋友圈看到一个段子，英伟达、DeepSeek们最大的壁垒，除了自身足够强大外， 也与“这个世界会汇编语言的人越来越少”有关。因为英伟达的CUDA以及DeepSeek需要使用类汇编语言级能力开发.

 

很多人都忽略了DeepSeek的软件开发能力。想从PTX层面对代码进行优化，难度无异于使用汇编语言对系统内核进行编程，这是只有极少数顶层开发者具备的编程能力，其复杂度相当于手绘一部《黑神话悟空》一样。正是因为有着强大的开发能力，DeepSeek才可与合作伙伴（如AMD、华为）深度合作，针对性优化推理效率。

 

在小雷看来，DeepSeek给行业带来的启发不只是“蒸馏”等模型实现本身，它还展示了绕过CUDA等老生态，从更底层的代码对AI大模型进行重构的巨大潜力，很可能会在行业掀起一股模仿潮流，让更多AI公司用汇编语言来进行底层优化。

**掀起多层变革，DeepSeek真正改变了世界**
==========================

 

在雷科技看来，DeepSeek给AI行业带来的变革是深刻的：

1、史无前例“便宜”的AI让AI有了工业化大生产的基础，给大规模商业化的AI产品如AI搜索的PMF（产品市场契合度）创造了可能，这很重要。互联网有Google等现象级应用，移动互联网有iPhone、微信等现象级产品，4G有抖音/TikTok等杀手级应用。如果一直没有全民级的AI杀手锏应用，AI产业终将是越吹越大的泡沫，迟早会破。

![图片](https://inews.gtimg.com/news_bt/O9ofMHWMatBKSG4BfhxLh8Y8hMTKANFkTn7zWmpk_oEagAA/641)

（图源：DeepSeek官网）

2、突破了英伟达在AI算力领域的封锁，突破了“OpenAI+英伟达”的制霸联盟，让更多软件AI开发者与芯片开发者可以抓住和推动AI浪潮，而这将进一步影响1。深层来看，DeepSeek也将助力世界各国突破美国在AI产业的制霸野心，让好的技术成为人人可用的工具，让所有主体在AI面前人人平等。

**3、开源力量的胜利，将让AI产业进行百家争鸣的创新阶段。**DeepSeek为AI行业提供了一个全新的开源范式，并且直观地展现了开源所带来的收益和效果。从闭源到开源，这或许就是AI生态的一个里程碑式的转折点。**高手在民间，真正的创新一定来自于成败上千万的开发者，而不是少数巨头。**

毫无疑问，华丽出水的DeepSeek和它的团队，在这个春节期间惊艳了世人，也真正意义上改变了世界。

![图片](https://inews.gtimg.com/news_bt/OU9MVxmpk91zd_86o-seYAonkFjTDqSvwf6Uw8NvfnEGsAA/641)

[qq](https://new.qq.com/rain/a/20250210A05RQI00)
