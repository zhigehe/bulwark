---
title: "胡泳：DeepSeek给我们带来怎样的世界？"
date: "2025-02-11 20:34:14"
summary: "图/ic文｜北京大学新闻与传播学院教授 胡泳 中国人工智能实验室DeepSeek推出的人工智能语言模..."
categories:
  - "qq"
lang:
  - "zh-CN"
translations:
  - "zh-CN"
tags:
  - "qq"
menu: ""
thumbnail: "https://inews.gtimg.com/om_ls/O21sat1FXB3CEJmaeGaPbB65qsg6Fw_xrKfncPvM3IVKUAA_640360/0"
lead: ""
comments: false
authorbox: false
pager: true
toc: false
mathjax: false
sidebar: "right"
widgets:
  - "search"
  - "recent"
  - "taglist"
---

![图片](https://inews.gtimg.com/om_bt/O0EZHK02o1z1BbsBIWOMJ6_5o3BbQS6UHhh-1XnBZ08XMAA/641)

**图/ic**

**文｜北京大学新闻与传播学院教授 **胡泳****

中国人工智能实验室DeepSeek推出的人工智能语言模型R1堪称一场地震。它在所有应用商店榜单上超越了美国的竞争对手ChatGPT，触发科技股市高达1万亿美元的抛售，并在硅谷引发末日般的评论。

美国知名风险投资家马克·安德森（Marc Andreessen）将R1的发布誉为全球人工智能发展竞赛中的“斯普特尼克时刻”（Sputnik moment），比肩当年苏联通过发射卫星而令冷战对手美国震惊的历史性事件。

对美国人的震惊有多大呢？英伟达，作为为AI模型提供支持的领先计算机芯片制造商，股价暴跌17%，市值蒸发近6000亿美元，跌幅创美国股市最高纪录。谷歌母公司损失了1000亿美元，微软损失了70亿美元。美国总统唐纳德·特朗普表示，DeepSeek应该成为“美国行业的警钟，我们需要全力以赴，专注于竞争以取得胜利”。

根据DeepSeek的说法，其R1模型在“各种基准测试”中表现优于OpenAI的o1-mini模型，而Artificial Analysis的研究表明，R1模型在整体质量方面也超越了谷歌、Meta和Anthropic开发的模型。

业界的震动不仅源于质量的高低，还在于DeepSeek声称仅花费不到600万美元就训练出了一款可与ChatGPT媲美的人工智能模型。相比之下，OpenAI的主要合作伙伴微软计划今年在人工智能基础设施上投入约800亿美元。

DeepSeek拿出的，不仅仅是“中国的ChatGPT”, 还代表着中国对OpenAI的回应，R1的影响要大得多，原因有几个方面。

**思维链模型：推理飞跃**

首先，它是一种“思维链”模型，这意味着当你给它一个查询时，它会通过自我推理来给出答案：这种技巧看似简单，但极大地提高了回答质量。

反复测试表明，DeepSeek-R1在解决数学和科学问题方面的能力与OpenAI于2024年9月在旧金山发布的o1模型相当，而后者的推理模型被认为是行业领先者。

OpenAI当时表示，o1的工作方式比以前的大语言模型（LLM）更接近人类的思维方式。“在回答之前进行思考，先生成一条长长的内部思维链再响应用户”, 这是OpenAI对其自身创作的描述。

在此方面，R1不仅可以直接与o1进行比较，还增强了自身回答数学和编程问题的能力——这些问题在AI专家中被高度重视。不仅如此，R1的能力不限于数字和代码，它在语言处理和自然语言推理任务中的表现也令人印象深刻，这意味着其高效的方法适用于更广泛的应用，而不仅仅是结构化问题求解。

此外，R1还更具可访问性。它不仅通过应用程序免费提供使用（而OpenAI的o1则需要每月支付20美元），而且对于开发者来说，完全免费，可以下载并集成到他们的业务中。例如，基于其出色的性能和低成本，R1将鼓励更多科学家在日常研究中尝试使用大语言模型，而无需担心成本问题。

除了低成本，R1的开放性可能会给科学研究带来颠覆性的变化：通过其应用程序接口（API），研究人员仅花费专有模型成本的一小部分即可使用该模型，或者通过在线聊天机器人DeepThink免费查询。此外，他们还可以将该模型下载到自己的服务器上，免费运行并在此基础上进行开发——这是像o1这样的封闭模型所无法实现的。

从人工智能研究的角度来说，DeepSeek展示了一种改进无数其他模型的方法。它通过使模型构建变得更便宜、更快速、更易于获取，代表了全球AI的重大进展。虽然LLM并不是通向先进AI的唯一途径，但DeepSeek的创新当得起“AI里程碑”的美誉。

Anthropic的联合创始人杰克·克拉克（Jack Clark）表示，该公司的模型Claude也受到启发。

*“现在互联网上出现了一个开放权重的模型，任何足够强大的基础模型都可以通过它引导成为一个AI推理器，”*

克拉克在他的新闻简报Import AI中写道：

*“全球的AI能力刚刚实现了一次不可逆的进步。”*

Anthropic另一位联合创始人达里奥·阿莫迪（Dario Amodei）则撰文表示，这背后是范式的改变。

*“每隔一段时间，正在扩展的基础事物会发生一些变化，或者在训练过程中加入一种新的扩展方式。从2020年到2023年，主要的扩展内容是预训练模型：这些模型通过大量的互联网文本训练，并在其基础上进行少量额外的训练。而在2024年，使用强化学习（RL）来训练模型生成思维链的想法，成为了扩展的一个新重点。这个新范式的特点是，首先使用普通类型的预训练模型，然后在第二阶段通过RL增加推理能力。”*

DeepSeek在构建其R1模型时的重大创新是摒弃了人工反馈，设计算法来识别并纠正自身的错误。研究人员写道：

*“DeepSeekR1-Zero展示了自我验证、反思和生成长链推理等能力……值得注意的是，这是首次通过强化学习验证大规模语言模型的推理能力可以仅通过这种方式进行激励。”*

总之，DeepSeek先进的推理能力、创新的训练方法以及对可访问性的承诺，为人工智能的发展树立了新的标准。阿莫迪特别提到：

*“我怀疑R1引起如此多关注的主要原因之一在于，它是第一个向用户展示模型推理过程（链式推理）的模型，而OpenAI的o1仅向用户展示最终答案。DeepSeek证明了用户对这一点感兴趣。”*

他认为，这仅仅是一个用户界面设计的选择，与模型本身无关。

然而，所有这些因素使得R1的表现更容易被人们欣赏，就像2022年ChatGPT的聊天界面首次使人工智能变得触手可及一样。

**挑战硅谷现成叙事****颠覆AI发展方式**

其次，R1的创建方法削弱了硅谷目前的AI发展方式。美国主导的方式是通过简单地增加更多的数据和计算能力来扩展现有模型，以实现更高的性能。这种方法导致了该行业能源需求的巨大增加，并使科技公司与政客紧密相连。开发AI的费用如此庞大，以至于科技公司希望借助国家来融资和兴建基础设施，而政客则希望购买它们的忠诚，并在支持高速增长的公司方面表现积极。

一个典型的例子就是特朗普在1月早些时候宣布的5000亿美元“星际之门”（Stargate）计划，号称“历史上最大的人工智能基础设施项目”——一个由OpenAI、甲骨文和软银联合投资的合资项目，旨在在全美范围内建立数据中心网络，目标是建设支持人工智能开发所需的关键数据中心和计算基础设施。

然而，在R1问世之后，特朗普说他一直在“阅读有关中国DeepSeek”及其公司的内容，特别是一家提出了“更快且更低成本的人工智能方法”的公司。“这很好，因为你不需要花费那么多钱。我将其视为一种积极的因素，一种资产，”特朗普表示。

市场对旧AI发展方式受到的冲击反应迅速且猛烈。《金融时报》报道称，对冲基金Elliott Management在一份致投资者的通知中表示，人工智能被“过度炒作”，而作为这一热潮的大赢家之一的英伟达正处于一个“泡沫”之中。

作为主导AI行业的芯片供应商，人们把英伟达与19世纪加利福尼亚淘金热时期的“铁锹和水桶商”作比较，因为它恰好在金矿高潮中出现，成为世界上最富有行业的主要供应商。然而随着DeepSeek的崛起，科技公司可能会开始质疑是否还需要像以前那样大量购买英伟达的工具。

从长远来看，AI领域的新竞争者对英伟达来说，会是个好消息吗？其他公司在AI军备竞赛中投入的计算能力是否代表了浪费的资金？通过开发出一个与美国同行相匹敌、在许多方面超越它们的AI模型，DeepSeek挑战了硅谷的故事，即技术创新需要庞大的资源和最小的监管。

DeepSeek做了什么是财力雄厚的OpenAI没有做到的呢？很难确定答案，因为OpenAI对其GPT-o1模型的训练过程一直非常保密。不过，两家公司在方法上的一些明显差异，以及DeepSeek似乎在某些领域取得的令人印象深刻的突破，都值得关注。可能最大的差异，也是导致像英伟达这样的芯片制造商股票暴跌的原因，在于DeepSeek能以远高于其规模对手的效率创造出竞争模型。

OpenAI能否转向高效？当然可以。但其与微软的合作伙伴关系和问题重重的领导结构可能使这种转变昂贵得多。这家公司深度整合了微软的Azure基础设施，曾经看似是战略优势，不过现在看起来越来越像一种负担。虽然OpenAI一直在推动客户转向微软庞大的数据中心，但市场正在发现一条不同的道路：高效的开源AI模型，可以在明显更便宜的基础设施上运行。

![图片](https://inews.gtimg.com/om_bt/OZFgLcA2XZiCY49fiLxDo52Q_B93_cAnxVE1up6WnXBwoAA/641)

OpenAI的方式与新兴的轻量级、可访问AI之间的鲜明对比使得该公司面临一个特别困难的局面。它的整个商业模式，建立在高昂定价和假设先进AI需要云计算和庞大数据中心的前提下，正在受到竞争者的挑战，后者通过更加精简的操作取得了大致相当的结果。

近年来，OpenAI通过将现有的机器学习算法扩展到前所未有的规模，在语言处理领域实现了一系列令人瞩目的突破。其GPT-4可能是通过使用数万亿单词的文本以及数千个强大的计算芯片进行训练的，整个过程耗资超过1亿美元。

然而，早在2023年4月，公司CEO山姆·阿尔特曼（Sam Altman）就表示，进一步的进展不会来自于模型规模的继续扩大。

*“我认为，我们已经到了这个巨型模型时代的尽头，我们会以其他方式改进它们。”*

此声明表明，GPT-4或许是OpenAI通过扩大模型规模并输入更多数据这一策略所产生的最后一次重大进展。当时，阿尔特曼并未说明将取而代之的研究策略或技术可能是什么。在描述GPT-4的论文中，OpenAI表示，其估算结果显示，扩大模型规模的回报出现递减。阿尔特曼还说，公司能够建设数据中心的数量以及建设速度也存在物理限制。

不过这并不妨碍包括Anthropic、AI21、Cohere和Character.AI在内的许多资金充裕的初创公司，投入巨大的资源，致力于构建越来越大的算法，试图赶上OpenAI的技术。直到DeepSeek出现的时刻。

R1颠覆了“扩展是前进之路”的普遍认知**。**据认为，R1的开发成本比OpenAI的o1便宜95%，而且仅使用了Meta的Llama 3.1模型十分之一的计算能力。能够以极小的预算实现等效的性能，才是R1令人震惊之处，这也是它发布后产生巨大影响的原因。这表明，美国公司可能在浪费资金，且更灵活的竞争者能够击败它们。

DeepSeek粉碎了“AI霸主地位需要亿万美元支票”的神话。更进一步地，DeepSeek的发展引发了对AI基础设施（如芯片）重大投资必要性的质疑，并对美国科技公司在AI领域的市场领先地位产生了影响，这可能会对美国科技行业的估值施加压力。

美国投资银行高盛的分析师在2024年6月发布了一份题为《生成式AI：过多的支出，过少的收益？》的报告，敲响了AI投资的警钟。该报告质疑未来几年内对AI的1万亿美元投资是否“值得”，并表达了对投资回报的担忧，而这种担忧现在被DeepSeek的案例所加剧。

如同Forrester的分析师所说。DeepSeek刚刚“打开”了AI投资回报的路径。由于精妙的优化，训练模型的成本壁垒大幅降低，预计这些优化方法将被全球的模型开发者复制并改进。

短期来看，这对英伟达来说是个坏消息，因为它将抑制需求。然而，从长期来看，较低的成本（以及因此而降低的能耗）将为更多的初创企业和企业提供创建模型的机会，从而增加整体需求。这进一步验证了一个事实：仅依靠提供核心AI基础模型的供应商是不够的，此一颠覆性转变将进一步打开AI模型市场的大门。对于技术领导者而言，这应该是一个强烈的信号，要求他们认真审视对AI领域几个大玩家的过度依赖。

**AI应该人人能负担并可获取**

所有这一切都意味着R1发布的确切影响是无法预测的。涉及的因素太复杂，未知数太多，无法确定未来会怎样。然而，这并没有阻止科技界和市场的疯狂反应，CEO们惊慌失措，股价暴跌，分析师们急忙修正行业预测。而这实际上正展示了AI领域的特点：它充满了热度、不确定性和过度反应。

可以确定的是，实现下一个层次的人工智能仍然需要大量的计算资源。推动我们迈向下一个里程碑的因素仍然不确定——是规模、数据、微调、强化学习，还是完全不同的其他因素。DeepSeek目前代表了我们所知道的最先进技术，但它并不是下一个层次的人工智能。

不过我们仍然可以断言：DeepSeek R1代表了人工智能发展中的一个重要里程碑。AI行业现在正处于十字路口：通往AI主导地位的道路可能不再是由庞大的数据中心和巨额预算铺就，而是通过优雅的算法和无情的高效性，最终将人工智能从象牙塔带入到大众手中。

在接受中国媒体采访时，梁文锋表示：“AI应该是人人都能负担得起并可获取的。”这一点，就是DeepSeek的最大意义之所在。

编辑 陈莉 校对 穆祥桐

[qq](https://new.qq.com/rain/a/20250211A088XY00)
