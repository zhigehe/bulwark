---
title: "百度大模型开源，折射AI产业竞争逻辑转变 | 宁可直说"
date: "2025-02-14 14:24:15"
summary: "2024年百度创始人李彦宏提到“开源模型是一种智商税”言犹在耳，不到一年，百度就宣布文心大模型4.5..."
categories:
  - "qq"
lang:
  - "zh-CN"
translations:
  - "zh-CN"
tags:
  - "qq"
menu: ""
thumbnail: "https://inews.gtimg.com/om_ls/OMsGa6TslK-1qh74-Z8Y_M4ooJSpE5fpsgAA-np2V0i3IAA_640360/0"
lead: ""
comments: false
authorbox: false
pager: true
toc: false
mathjax: false
sidebar: "right"
widgets:
  - "search"
  - "recent"
  - "taglist"
---

![图片](https://inews.gtimg.com/om_bt/O-Fi8FBbNqA-1yCpjT2jhReYWg8ax7SN175k0Ou8ksC2IAA/641)

2024年百度创始人李彦宏提到“开源模型是一种智商税”言犹在耳，不到一年，百度就宣布文心大模型4.5系列将于2025年6月开源，并同步推出免费服务。

这种戏剧性的战略转向，折射出AI行业竞争逻辑的变化：从比拼参数规模的“军备竞赛”转向争夺开发者生态的“生态位战争”。

“玉在椟中求善价，钗在奁中待时飞”，再好的技术没人用也白搭。百度若固守闭源路线，风险之一就是面临开发者和使用者的流失——这也是其相关产品和云服务接入DeepSeek-R1开源模型的原因之一。当然，也不必否定文心一言此前的闭源路线，从市场渗透率来看，用户规模（4.3亿）与调用量（日均15亿次）均居国内前列，2024年11月百度文心智能体平台吸引了15万家企业和80万名开发者。

只是当参数规模突破千亿后，单纯堆砌算力的收益急剧衰减，效率革命正在倒逼架构革新，大模型研发逻辑的调整是必然。开源社区通过模型剪裁和架构优化（如MoE混合专家模型），在同等算力下实现更高效率，DeepSeek V3采用MLA（多头潜在注意力）架构就是一个最现成的例子。而从商业视角来看，特别是R1模型火了之后，云厂商、服务器厂商和芯片厂商都站出来表示可以提供更好的服务优化用户体验，“开源引流+云服务变现”的路径客观上推动了大众拥抱新技术的热情，也带来AI变现的实惠。能不能边赚钱边研发，还是先把钱赚了？怎么选都有公司的道理。

不过，早期“闭源护城河”思维有没有多多少少隐含技术霸权逻辑？这得李彦宏自己来说。但是在生成式AI的早期探索阶段（2022-2024），百度选择闭源路线具有技术合理性：当ERNIE 3.5 Titan（260B参数）处于性能快速提升期时，闭源能保护核心算法优势。随着模型效能进入边际递减阶段（2024年后），参数规模突破千亿带来的提升成本急剧上升，此时开源成为激活场景创新的必要选择。这种转变符合技术成熟度曲线规律——当基础技术突破完成后，生态构建成为价值捕获的关键。

我想AI产业从来不是“技术单极”而是“生态多极”。当参数规模突破万亿后，竞争焦点不再是单一模型性能，而是生态系统的活性与延展性。大公司的摇摆从来都是审时度势。只不过就像那句最近很火的台词“人心中的成见是一座大山”，愿不愿意夸一句当事人“识时务者为俊杰”就不一定了。

百度的摇摆如此醒目，至少是一种提醒：未来，开源与闭源的边界可能进一步模糊——既开源基础模型又保留商业版本，形成“开放核心+增值服务”的混合模式可能成为新的商业模式。企业的胜负将取决于能否构建“技术底座—开发者-数据-场景”的正向循环。

 (本文来自第一财经)

[qq](https://new.qq.com/rain/a/20250214A04RZS00)
