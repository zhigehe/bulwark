---
title: "“80元部署个人语音助手”！DeepSeek开启AI普惠时代 端侧应用打开想象空间"
date: "2025-02-08 08:29:13"
summary: "《科创板日报》2月8日讯（记者 郭辉） “80块打造个人语音助手”、“150块DIY豆包智能机器人”..."
categories:
  - "qq"
lang:
  - "zh-CN"
translations:
  - "zh-CN"
tags:
  - "qq"
menu: ""
thumbnail: "https://inews.gtimg.com/om_ls/OiNc507dA-ssxeRaqd19ipce64CpS1aR5HvZYd805YtXcAA_640360/0"
lead: ""
comments: false
authorbox: false
pager: true
toc: false
mathjax: false
sidebar: "right"
widgets:
  - "search"
  - "recent"
  - "taglist"
---

**《科创板日报》2月8日讯（记者 郭辉）** “80块打造个人语音助手”、“150块DIY豆包智能机器人”……随着DeepSeek的爆火，个人用户部署AI大模型一夜间“出圈”。

科技界围绕AI降本所做的工作并非一夕之功。有业内人士表示，DeepSeek在算法层面的推理成本优化，为国产算力芯片和计算集群网络等硬件端的发展争取了更多空间，而软硬件成本的减少，也将相应为国内AI应用带来机会，由此形成产业发展正向循环。

越来越多个人开发者低成本的AI模型部署实践，让公众更加清醒地认识到，AI普惠时代已来，端侧AI落地箭在弦上。PC产品被认为是端侧AI模型落地的首站。而受访的供应链人士认为，当前更大的想象空间还在智能眼镜、AI玩具等智能体等应用中，DeepSeek带来的轻量化模型，将为智能终端行业带来积极影响。

**个人用户部署大模型火爆 40元开发板月售万件**

“80块买一块开发板，按照教程进行硬件连接和固件烧录，就能接入DeepSeek等大模型，打造个人语音助手系统。”在技术社群中，有开发者分享了部署AI的技术帖。

不仅如此，《科创板日报》记者关注到，花150元还能自行搭建一个豆包智能机器人，358元能搭建接入大模型且具备手势识别、触摸交互的机器人……可以说，DeepSeek近期的持续爆火，使得AI大模型部署的知识交流同样火热，也让低成本搭建AI智能工具进入更广泛的公众视野。

“万能的淘宝”和技术开源贡献，让这一切加速走进现实。

据了解，以上方案均基于乐鑫科技的ESP系列芯片。在淘宝搜索ESP32关键词，可以看到包括乐鑫官方企业店在内，有多个商家售卖开发板或套件，不同套件价格低可至20元、配备屏幕及扬声器、麦克风的套件价格可高至340元。

![图片](https://inews.gtimg.com/om_bt/O6Fvquhll1kTJjRj1EQEFg6E3QWduKxkATn0CqmgOueYoAA/641)

《科创板日报》记者关注到，一套价格80元的聊天机器人ESP32-S3开发套件，全网销量已超1000件；价格40元的ESP32-S3开发板，则显示月售超1万件。

在评论区中，消费者以个人开发者居多。在购买商品后，商家会附送教学视频，同时还会为用户提供技术支持。

“一站式搞定，新手小白也可以操作”、“老板教我教到（晚上）12点半”、“老板晚上10点还在教我烧录”……多名买家如是反馈产品购买体验。

![图片](https://inews.gtimg.com/om_bt/OSHumN-LaUh78M6vCtrMwusbxfYkiXKgs8kaAYCyIpZnwAA/641)

据乐鑫科技介绍，其ESP32-S3芯片硬件具备加速神经网络计算和信号处理等工作的向量指令，AI开发者们通过ESP-DSP和ESP-NN库使用这些向量指令，能够实现高性能的图像识别、语音唤醒和识别等应用。

有开发者称，ESP32-S3支持在本地离线运行一些AI模型，比如语音识别、人脸识别和移动检测。但大部分自然语言对话交互仍需要线上接入大语言模型。

除乐鑫科技外，恒玄科技、中科蓝讯、炬芯科技等公司的SoC芯片在终端AI部署中有所应用。

其中，恒玄科技应用于可穿戴设备中的BECO嵌入式AI协处理器，能够和主CPU核心配合工作，完成基于神经网络AI算法的音频处理，同时保持较低功耗水准。

炬芯科技则在其最新一代产品中整合了低功耗AI加速引擎，采用基于SRAM的存内计算技术，同时将产品逐步升级为CPU、DSP加NPU的三核异构计算架构，打造低功耗端侧AI算力。

**产业链人士：看好DeepSeek对AI端侧的积极影响**

DeepSeek的横空出世，为端侧AI落地应用进一步打开想象空间。

据了解，通过蒸馏，大模型推理能力可迁移至小参数模型，能够大幅提升AI部署的灵活性。据光大证券分析师刘凯在2月6日发布的研报称，蒸馏模型有1.5B、7B、8B、14B、32B、70B等多个版本，虽然蒸馏会损失部分能力，但更小的参数意味着更大的灵活性。第三方可以从DeepSeek-R1中蒸馏出更多版本的小参数模型并部署至手机、笔记本电脑、智能家居产品等各类终端产品中，预计将助力硬件销量提升、并涌现出更多基于AI服务的付费点。

端侧AI落地来势汹涌，其前景也得到了产业链人士的证实和看好。

一家存储芯片厂商人士则向《科创板日报》记者称，**DeepSeek对于AI端侧的存储有积极的影响，目前尤其看好端侧AI智能眼镜产品当中的落地。从行业来看，海外公司Meta的AI眼镜是32GB容量+2GB的配置，大模型在其中已经能够当成本地化工具来使用，而未来可能智能眼镜存储容量还要加大。**

该人士称，**“预计今年国内的智能眼镜肯定会大爆发，起量会在2026年。”**

一家国内消费电子配套芯片公司人士向《科创板日报》记者表示，**尽管他们的产品在产业链几乎最上游，但还是能感受到DeepSeek为智能终端行业带来的积极影响。“AI降本之后，终端应用预计会有大的爆发，继续看好眼镜、玩具、AI手机、AI PC等消费电子。”**

华安证券分析师陈耀波在2月6日发布的研报中表示，端侧实现AI能力需要端侧AI大模型的落地。从国内手机整机厂商看，均推出文档摘要、AI修图等端侧AI功能，包括华为的盘古模型、小米的MiLM、vivo的蓝心大模型等，基于DeepSeekR1在推理能力上表现出色，若能进入AI智能终端，将推出具有强大AI功能的产品，有望提升用户体验。

以AI眼镜的产业链为例，光大证券表示，看好与日常需求相结合产生的巨大市场空间，建议关注恒玄科技、中科蓝讯、星宸科技、富瀚微、云天励飞-U、炬芯科技等SoC芯片商；以及普冉股份、兆易创新、佰维存储、长盈精密等零部件环节。

**DeepSeek为国产硬件端发展争取更多空间**

PC产品同时包含生产力工具和个人智能管家两大属性，被认为是端侧模型落地的首站。以部分PC主机厂为主导，DeepSeek模型与国产算力芯片的适配进展超过不少人的想象。

《科创板日报》记者了解到，**日前搭载龙芯中科3A6000处理器的信创PC宣布实现DeepSeek本地化部署**。据诚迈科技表示，DeepSeek实现本地部署后，无需依赖云端服务器，避免了因网络波动或服务器过载导致的服务中断，并且也保障了信息安全。比如在党政机关等涉及大量敏感信息和个人隐私的场景中，用户通过诚迈信创电脑上的本地部署DeepSeek，能够完成文档处理、数据分析、内容创作、图片编辑及代码生成等多项工作，防止数据外泄。

**国产GPU厂商沐曦则与联想合作，推出了面向敏捷部署的DeepSeek智能体一体机解决问题。**该产品搭载的联想AI Force智能体开发平台，深度融合DeepSeek等主流大模型库，并通过私有化部署实现安全合规以及高度定制化、再开发能力等。实测数据显示，在相同并发条件下，沐曦曦思N260 GPU在Qwen2.5-14B模型推理实测性能达到NVIDIA L20 GPU的110%-130%，可支持本地部署DeepSeek各种参数蒸馏模型推理。

除了本地化部署，DeepSeek作为开源模型，还通过各大云计算平台向中小企业及个人用户提供AI服务资源。

有业内人士向《科创板日报》记者表示，从商业模式上来看，目前DeepSeek处于开源状态，云计算平台方遵循开源协议均可使用。对用户而言，算力平台可能会附加算力成本或相关服务成本，但考虑到算法模型公司的资产投入，云计算平台作为“卖水人”，相对而言仍是高效稳定的选择。**事实上，“近期DeepSeek火热，使得算力平台需求明显增多”。**

**该人士还表示，基于主流云平台异构计算方案，DeepSeek也在一定程度上推动国产大算力芯片和异构计算方案被市场接纳，进一步降低了AI训练成本。**

目前，阿里、腾讯、超算互联网等算力平台，均已经上线DeepSeek系列模型。在算法和算力网络的共同优化之下，云计算平台对DeepSeek模型进行适配并提供服务，降低了终端接入大模型的成本和部署门槛。

以阿里云为例，用户无需编写代码，即可云上一键部署DeepSeek-V3、DeepSeek-R1，实现从模型训练到部署再到推理的全过程，极大地简化了AI模型的开发流程。在价格成本方面，阿里云服务用户可选取公共资源组搭配节省计划，或购买预付费EAS资源组等方式来节约成本。超算互联网平台则无需用户部署或进行复杂操作，可开箱即用DeepSeek模型，并提供不限量免费体验服务。

**“端侧大模型的线上接入，相对本地部署更为容易，但整体来看，DeepSeek确实让更多AI应用落地的软硬件成本有所减少。”有算力产业人士表示，DeepSeek在算法层面的优化，给了国产硬件端的发展争取了更多空间，相应地也为国内AI应用带来机会，并进一步强化了国产AI从算法、算力到应用的生态闭环。**

（科创板日报记者 郭辉）

[qq](https://new.qq.com/rain/a/20250208A01KII00)
