---
title: "小模型逆袭Deepseek和OpenAI？"
date: "2025-02-12 18:30:43"
summary: "大模型可谓日日新，大规模的“重量级选手”到高效的小模型，“轻量化”最近正成为热潮。传统的大模型就像是..."
categories:
  - "iyiou"
lang:
  - "zh-CN"
translations:
  - "zh-CN"
tags:
  - "iyiou"
menu: ""
thumbnail: ""
lead: ""
comments: false
authorbox: false
pager: true
toc: false
mathjax: false
sidebar: "right"
widgets:
  - "search"
  - "recent"
  - "taglist"
---

大模型可谓日日新，大规模的“重量级选手”到高效的小模型，“轻量化”最近正成为热潮。

传统的大模型就像是“巨人”，体量庞大，推理能力强，但也正因为“庞大”，才带来了“资源”的沉重负担。

最近，低成本AI推理技术崛起，越来越多的小模型横空出世，用其灵活性和高效性，在推理任务中展现出了“巨人”才具备的强大能力。

### **从“大”到“小”：逆袭大佬**

传统的大模型——庞大的计算需求、庞大的存储占用，和与之对应的高昂成本，**让其在实际应用中成为了“高岭之花”。如果AI只依赖“大模型”的“坚硬外壳”，我们可能会错失了“轻巧武器”带来的独特优势。**

这俩天，普林斯顿大学、北京大学、清华大学等研究员们纷纷大展身手。

通过Test-Time Scaling (TTS)和ReasonFlux框架等技术的突破，让小模型逆袭**Deepseek和OpenAI**，在数学推理等高难度任务中大放异彩。**所以，“细流”的力量也是有可能突破”江河”束缚的。**

### **ReasonFlux：小模型成“快剑”，一刀切复杂问题**

如果将AI推理比作一场复杂的棋局，那么ReasonFlux框架就是那根“精妙的棋杆”。

**今天，由普林斯顿大学与北京大学联手提出的ReasonFlux框架正式发布并在GitHub开源，**通过“分层推理”技术，给AI推理能力装上“快递包裹”轮子，使得小模型可以以更少的计算资源，完成更加复杂的数学任务。

ReasonFlux让小模型“精简高效”，无论面对什么样的难题，都能快速应对，逐步拆解难题。

其提出的分层强化学习，主要是首先从大量的数学问题中提取了约500个结构化的思维模板。每个模板都包含标签、描述、适用范围、应用步骤等信息，

利用这些思维模板，对基础大语言模型（LLM）进行微调，使其深入理解每个模板的结构、内容和用途，微调后的模型会根据输入问题，分析并抽象出核心数学概念，配置出模板轨迹。

通过在类似问题上的求解准确率来衡量轨迹的好坏，再用这个奖励信号优化模型，让它不断改进规划的轨迹。

再通过层次化强化学习训练一个高层次的导航器（navigator），使其能够对输入问题进行拆解，转而求解多个更简单的子问题。

**通过这种方式，32B的小模型，在面对AIME等数学基准测试时，直接“挑战”大型模型的霸主地位，轻松超越OpenAI的o1-preview、Deepseek的V3，刷新推理领域的“速度纪录”。**

![](https://diting-hetu.iyiou.com/async/weixin/TdQZI57wwt9YqvpmV4My)

### **TTS策略：小模型的“计算化身”，超越大模型**

另一个帮助小模型突围的技术是Test-Time Scaling (TTS)。

也是在推理时精细分配计算资源的“妙法”。

2月10号由多人多机构联合产出上传的论文“1B参数的大语言模型能否超越405B参数的大语言模型？重新思考计算最优的测试时扩展”震撼AI圈。

![](https://diting-hetu.iyiou.com/async/weixin/NY2oUPQW1CoIh1MzkjdG)

TTS策略能够让小模型“量体裁衣”，根据问题的复杂度灵活调节推理所需的计算资源。更像“专将出征”，根据敌情变化灵活调整战术，面对更复杂的敌人，指挥官会“精打细算”调配兵力，而面对简单的敌人，则可以以少胜多。**通过TTS策略，1B小模型能够超越405B的大模型，堪比“鲤鱼跳龙门”了……**

在这篇论文里，作者通过不同策略模型、PRMs（Policy Response Models）的角度以及更具挑战性的评估任务方面，对计算优化的测试时扩展（compute-optimal test-time scaling, TTS）进行了深入的实证分析。

研究发现，计算优化的TTS策略依赖于策略模型、PRMs和问题难度，验证了在应用计算优化的TTS时，较小的语言模型可能比更大的模型表现更好。

可以说，TTS不仅“解锁”了小模型的潜力，还让它们迎头赶上，超越了那些因庞大计算需求而变得迟缓的大模型。

### **推理优化：从“大象起舞”到“小巧灵活”**

如何让小模型在不增加计算资源的情况下，依然能展现出“大模型”的推理能力呢？

推理优化技术提供了解决方案。小模型的灵活性和高效性，让它能够在“少”中追求“多”，通过精准的推理“步伐”逐步突破难关。

微软亚洲研究院也曾在上个月推出的新算法 rStar-Math，通过引入类似人类系统的慢思考和推理思维，也显著提升了小语言模型（SLMs）的数学推理能力。

这种优化思路通过不断提升推理过程中的“思考”方式，让小模型在面对复杂的推理任务时，展现出“巧妙”优势。

### **低成本小模型应用的未来不远了**

小模型在AI领域的崛起如火如荼地展开。从数学推理到商业应用，低成本小模型不仅能够实现高效推理，还逐渐走向实际应用。低成本的小模型正逐步“走向大众”，突破了大模型“高冷”的局限，使得更多的公司、机构、乃至个人都能享受到这一新技术带来的红利。

可以想象，在不久的将来，随着硬件设施和云计算服务的进一步发展，AI的“门槛”将变得更加低，帮助更多的人迈入智能化时代。从“大型模型”的“庞大身影”，到“小模型”的“高效身手”，AI正在向着更加“灵动”、普惠的未来跃进。

[iyiou](https://www.iyiou.com/analysis/202502121090082)
