---
title: "DeepSeek，搅了谁的局？"
date: "2025-02-10 16:26:13"
summary: "上一次AI行业引起全民震动还是2022年11月ChatGPT的横空出世，此后AI行业每逢重大变革，都..."
categories:
  - "iyiou"
lang:
  - "zh-CN"
translations:
  - "zh-CN"
tags:
  - "iyiou"
menu: ""
thumbnail: ""
lead: ""
comments: false
authorbox: false
pager: true
toc: false
mathjax: false
sidebar: "right"
widgets:
  - "search"
  - "recent"
  - "taglist"
---

上一次AI行业引起全民震动还是2022年11月ChatGPT的横空出世，此后AI行业每逢重大变革，都被称为是“ChatGPT时刻”。

这个词在2024年年底被改写，**“DeepSeek时刻”出现，被看作是AI历史上的新转折点。**

2025年春节前期，中国杭州的一家AI企业DeepSeek（深度求索）接连发布了V3（2024年12月26日）和R1（2025年1月20日）两大开源模型。

其中，DeepSeek宣称V3在性能上接近闭源模型OpenAI的GPT-4o与Anthropic的Claude-3.5-Sonnet，优于开源模型Meta的Llama 3，且总训练成本仅为557.6万美元。推理模型R1的效果则逼近OpenAI o1，同时API（应用程序编程接口）价格仅为OpenAI o1的3.7%。

这是一家成立于2023年7月17日的初创公司，手上却握着万张英伟达芯片，以海外AI巨头们7%左右的成本训练出了性能不错的大模型。这家公司早在2024年5月发布V2模型后，正式打响中国大模型价格战，被字节、阿里、百度等大公司盯上，年底又成功将价格战烧到海外。

DeepSeek的出现，一度让全球算力概念股暴跌，叠加美股科技股普跌的影响，英伟达股价下跌近17%，市值蒸发近6000亿美元，规模创美股史上最大。OpenAI和谷歌也在近期紧急上线最新模型，AI行业堪称烈火烹油。

DeepSeek爆火之后，硅谷巨头们开始掀桌，OpenAI表示已经发现证据，证明DeepSeek“蒸馏”OpenAI模型的迹象，Anthropic创始人和CEO Dario Amodei发文否认R1取得的突破，并呼吁加强对中国的算力出口管制。抛开这场盛宴背后的情绪，本文试图理清，DeepSeek到底有没有被“高估”，以及DeepSeek将会对国内外AI产业带来哪些涟漪效应。

### **欲戴其冠，必承其重**

DeepSeek-R1上线20多天，接受了多少掌声，就承受了多少压力。

AI行业从业者林志向「定焦One」总结了DeepSeek口碑的来源：

1、完全免费使用。

2、在和用户聊天时会展示思维过程，这样也能反向优化用户的提问形式，提升对话体验，而o1就没有公布思考过程，原因可能是怕竞争对手将过程拷贝后训练自己的模型。

3、将技术论文和模型进行毫无保留的开源，部分开源大模型还是会将最好的版本留给自己。但前几天因为热度前来的用户发现，DeepSeek频繁出现宕机，几乎无法正常使用，原因是公司服务器受到了大规模DDoS恶意攻击，截至发稿，DeepSeek已恢复正常使用。

![图片](https://diting-hetu.iyiou.com/async/weixin/p4gPJeYDg42ORCD5XNP1)

DeepSeek表示服务运行稳定当然，上述特征只是让DeepSeek有了用户自发传播的基础，DeepSeek之所以火爆，一定程度上是因为它让海外AI巨头“破防”，出现了“掀桌子”的行为。

面对不少人士“DeepSeek是否有创新”的质疑，DeepSeek在其披露的V3和R1的技术论文中已经有过回应：

1、V3模型采用多项自研技术进行架构创新，包括DeepSeekMoE+DeepSeekMLA架构、MTP多Token预测技术，使低成本训练成为可能；

2、R1模型放弃了传统RLHF（人类反馈强化学习）中的HF部分，通过纯强化学习（RL）直接训练，验证了RL的优先级和有效性，进一步优化了训练效率。这也意味着，DeepSeek证明了自己的确可以做到“以不到600万美元的训练成本（可以理解为净算力成本），完成一个性能接近巨头的模型”。

不过，半导体市场分析和预测公司SemiAnalysis指出，557.6万美元这个数字主要指的是模型预训练的GPU成本，考虑到服务器资本支出、运营成本等因素，DeepSeek的总成本在4年内可能达到25.73亿美元。不可忽略的是，创新成本下降的趋势早已开始，DeepSeek只是加速了这一进程。

方舟投资管理公司的创始人兼CEO“木头姐”指出，在DeepSeek之前，人工智能训练成本每年下降75%，推理成本甚至下降85%到90%。英诺天使基金合伙人王晟也有相同看法，比如年初发布的模型，到年底再发布同样的模型，成本都会有大幅度下降，甚至有可能降至1/10。而且OpenAI作为闭源模型，对外披露的算力成本也有虚高的可能性，因为要留部分利润空间，也要不断对资本市场强化成本很贵的故事，以此得到更高的投资。不过，DeepSeek的可贵性并不仅仅在于“便宜”，更在于它是一个“屠龙少年”的故事。

在ChatGPT横空出世之前，在中国面临算力管制之前，DeepSeek就已经拥有了超万张的GPU储备。这关联到DeepSeek的创始人梁文峰从2008年开始探索的量化交易，因为要将深度学习模型应用于实盘交易，必须储备大量算力，2019年至2021年间，梁文峰的另一家公司幻方相继自主研发了“萤火一号”与“萤火二号”AI集群，囤积大量芯片和技术人才。

幻方为梁文峰提供了很多东西，足够的卡、对AI的sense以及模型层面的工程化能力，梁文峰也为DeepSeek提供了很多东西，不以盈利为导向，对AGI纯粹的好奇心和探索欲，以及足够开放的心态。有参与者表示，幻方曾用很低的价格将卡提供给算法研究机构使用。这样的故事具有不可复制性和美感，这也使得DeepSeek聚集了全民性的热度。

### **DeepSeek让谁慌了？**

DeepSeek火了之后，一石激起千层浪，中美AI产业链上下游的企业都受到了冲击。首当其冲的要数chatbot类（聊天机器人）AI应用，根据AI产品榜的数据，DeepSeek在2025年除夕前后，日活超过2000万，超越国内的豆包和Kimi登顶中国第一。同时，DeepSeek仅用一周就用户破亿，而ChatGPT用时2个月。

![图片](https://diting-hetu.iyiou.com/async/weixin/nb0b5AI8bNo5iNAP0G5q)

实际上，在DeepSeek发布R1的几乎同一天，月之暗面推出了自己的Kimi k1.5思考模型，并在Kimi免费开放使用，豆包APP也更新实时语音通话功能，面向所有用户开放，但是两者声量均被盖过，日活也受到影响。

林志认为，这件事充分展示了用户对chatbot这种模式的忠诚度是很低的，一旦出现了更强大更便宜更快的模型，大家就会迁移过去。不过，从产品形态来看，豆包已经在产品中接入多模态大模型，而DeepSeek目前还只有对话，且体验不稳定。虽然DeepSeek在除夕当天（1月28日）发布了开源文字生成图像（文生图）大模型Janus-Pro 7B，但是暂时还没有接入DeepSeek网页和APP中使用。

![图片](https://diting-hetu.iyiou.com/async/weixin/cPtXESyvgFGfuf1Grtcz)![图片](https://diting-hetu.iyiou.com/async/weixin/rTzt3SrbWSjJwSBwn71v)上为豆包，下为DeepSeek在真正的杀手级应用出现之前，比拼的还是背后的大模型能力。

在这个层面上来看，目前受到DeepSeek直接影响的第二批公司是自研大模型公司。从投资人的视角出发，王晟指出，从2024年5月DeepSeek发布V2模型打响中国大模型价格战时，圈内基本达成一个共识——国内巨头中，最好用的大模型是阿里的Qwen，豆包在2023年还不够好用但在2024年下半年提升很快；

创业公司里DeepSeek和月之暗面（Kimi）增长最快，其余五小龙（零一万物、MiniMax、百川智能、智谱AI、阶跃星辰），有的转型、有的放弃、有的背靠国资，但增长逐渐慢下去了，六小龙的格局也基本瓦解。某种程度上，这些闭源大模型公司也要面临和国外巨头一样的拷问：训练成本能不能降下来？有没有更高效的训练方式？API价格战还打不打？

至于DeepSeek是否会改变芯片市场的格局，多位行业人士则表示，算力之争不会消失，但是现在到了一个重估的阶段。之前英伟达的热度过高，现在股价只是回归到了合理区间，但是最终英伟达的价值还是会上去。也就是说，英伟达并非DeepSeek的受害者。反而是随着模型应用场景的扩展，模型越“平权”，对算力的需求越大。

DeepSeek把大家从一腔热血只追求AGI的上限，拉回到转向关注产业落地的现实里，它用很低的成本给到相对高的能力，能促进产业链上的创新，将利好AI原生应用和AI硬件的发展。“2025年将是AI商业化落地元年”，林志称。同时，DeepSeek验证了国内AI产业从芯片到模型是可以部分实现国产替代的，提振了产业信心。

春节期间，国内云服务厂商和GPU厂商纷纷部署DeepSeek。不过，随着一步步被推向“神坛”，DeepSeek的最大冲击或许将来自于自身的选择。有信源称，阿里正计划以100亿美元的估值，投资10亿美元认购DeepSeek10%的股权。这一估值已经超过月之暗面（33亿美元）和智谱AI（20亿美元）。

这一消息被阿里方面否定，也有人指出背靠幻方的DeepSeek一直没有寻求过融资，但市场仍担心还有其他战略方正在接触DeepSeek。这或许是市场最不想看到的结局，在这个春节接到“泼天富贵”的DeepSeek，原本是一家自由的公司，梁文锋也曾对媒体提到，与大厂模型的最大区别是，“大厂会和平台或生态捆绑，而我们是完全自由的”。有人担心如果DeepSeek此次拿了任何战略投资方的钱，AI六小龙的故事或许将在它身上重现。

### **DeepSeek的新范式，还有成长空间**

放到更大视角来看，DeepSeek的崛起之所以被海外巨头如此重视，背后是两种路径的对比。王晟解释，AI产业在跑通AGI方向上往往有两种不同的路径选择：一个是“算力军备”范式，堆技术堆钱堆算力，先把大模型性能拉至一个高点，不断推高AGI的能力上限，再考虑产业落地；

另外一个是“算法效率”范式，一开始就以产业落地为目标，通过架构创新和工程化能力，推出低成本高性能模型。可以看到，以往大模型公司之间的竞争，基本都是押注“算力军备”范式。在这种范式下，OpenAI、Anthropic、谷歌，包括国内AI六小龙等企业，都是重资本投入型企业。

因为需要巨大的资金量，这意味着资本市场只能支持少数几家企业，AI巨头的市场集中度远高于其他行业。DeepSeek-R1发布之际，美国总统特朗普宣布了一个总额达5000亿美元的AI基础设施项目“星际之门”，OpenAI、软银和甲骨文等都已承诺参与其中。稍早前，微软表示2025年将在AI基础设施上投入800亿美元，扎克伯格则计划在2025年为其AI战略投资600多亿美元。

一个无法忽略的市场环境是，过去大家都在追求AGI能力的不断增长，只要模型性能增长的够快，竞争对手在后面无论怎么进行数据工程优化都追不上头部企业。但是到2024年11月左右，“高质量文本训练数据即将被消耗殆尽”的论调敲响了行业警钟，如果数据供应停滞，模型训练也可能停滞，大家意识到之前比较粗放的训练模式确实可能存在瓶颈，即使往上堆算力，延长训练时间和增大数据量级，能力增长也几乎到头了。

在这个时间点，其实也有企业认为“算法效率”范式是当下可行的范式，只是DeepSeek先做出来了。“它的一系列模型也证明了，在天花板涨不动的情况下，把重点放在优化效率而非能力增长上的范式也具有可行性。”王晟称。这样的背景下，DeepSeek以一个“搅局者”的身份出现，美国AI巨头“花钱砸模型很值”的资本故事逐渐不成立了。DeepSeek以开源模型入场，被视为是靠生态的力量去挑战领先者，而领先者为了怕被搅局，通常会越来越封闭。“其实中美的主流路线已经完全反过来了”，林志称。

在阿里Qwen性能追赶上来之前，全球最主流的开源模型是Meta的Llama，在海外市场，Llama一度落后于OpenAI跟Claude等闭源模型，但在国内，目前在大模型上支大旗的反而是开源模型。不过，也有不少业内人士认为不应该过分乐观，因为DeepSeek只能说是给2025年开了个好头，竞争还在继续，差距依旧存在。

近期，几大海外巨头就推出了新模型。2月1日，OpenAI发布最新推理模型o3-mini系列，这是OpenAI首个开放给免费用户的推理模型。2月6日，谷歌官宣Gemini 2.0家族更新，其中Gemini 2.0 Flash-Lite版本被称为谷歌目前为止性价比最高的模型。正如梁文锋自己所说，虽然具体技术方向一直在变，但模型、数据和算力这三者的组合是不变的。数据工程也是其中很重要的一环，OpenAI虽然面临侵权问题但积累了自己的数据库，豆包因为TikTok事件影响也宣称自己不会进行数据蒸馏，“原生搭建的数据库”成为大厂的护城河之一。

另外，王晟提到，根据Trade-off Curves（取舍曲线），DeepSeek选择的路径意味着它的精力重点在于工程优化，那就很难在能力上限上取得突破，“它用现有方法继续迭代新版本，能力能提升多少？这是个问题。”从学生时代起，梁文锋就展现出探索AGI的热情和不断创新的追求，DeepSeek此前只是躲开了无效或失败的尝试，但我们也不应该否认前一种路径中，巨头们不惜代价，通过各种未知的尝试来拓宽AGI边界的努力。DeepSeek搅动的这一片汪洋，涟漪还在继续扩大。\*文中林志为化名。

（首图来源：图虫）

[iyiou](https://www.iyiou.com/news/202502101089862)
